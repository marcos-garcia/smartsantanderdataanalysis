<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta name="author" content="Marcos Garc√≠a Casado" />
		<meta name="description" content="Smart Santander Data Analysis" />
		<meta name="keywords"  content="santander, smartsantander, data, big data, utad, marcosgarciacasado, marcos garcia" />
        <title>Smart Santander Data Analysis - Arquitectura</title>
        <!-- Bootstrap core CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
        <!-- Custom styles for this template -->
        <link href="stylesheets/carousel.css" rel="stylesheet">
    </head>
    <!-- NAVBAR
================================================== -->
    <body>
        <h1>Antecedentes</h1>
<p>En este apartado se habla del estado del arte de las Smart Cities y del proyecto SmartSantander en concreto, desde el cual se recogen los datos de los sensores de la ciudad de Santander, y que se utilizan como fuentes de informaci√≥n para su posterior tratamiento en la arquitectura Big Data desarrollada.</p>
<h2>Smart City</h2>
<p>Existen varias definiciones de lo que significa una Smart City, aunque todas concluyen en que es el empleo de las Tecnolog√≠as de la Informaci√≥n y de la Comunicaci√≥n, conocidas como TIC, para ofrecer servicios de informaci√≥n a nivel de zona urbana que permitan una mejora de ciertos elementos caracter√≠sticos de una ciudad, como pueden ser los servicios p√∫blicos, la sostenibilidad o la eficiencia de uso de sus recursos; e incluso suponer un impulso econ√≥mico importante para la ciudad.</p>
<p>Este t√©rmino se ha llevado usando desde hace m√°s de veinte a√±os. Comenz√≥ us√°ndose con fines energ√©ticos: monitorizar ciertos elementos que permitan optimizar el consumo de energ√≠a de una ciudad y conseguir un ahorro econ√≥mico y una mejora en su sostenibilidad (1).</p>
<p>Pero con el paso de los a√±os se han comenzado a utilizar las TIC para otros fines, como son ayudas para mejorar el transporte y en el tr√°fico de veh√≠culos en las ciudades, optimizaci√≥n de sistemas de climatizaci√≥n, construcci√≥n de edificios sostenibles, gobernanza y gesti√≥n de administraciones‚Ä¶</p>
<p>Telef√≥nica (1) describe las Smart Cities como aquellas ciudades que utilizan las TIC para dotar a sus infraestructuras de herramientas que permitan la interacci√≥n del ciudadano con los elementos urbanos. La considera como una plataforma en la que muchos agentes de distintos tipos pueden interactuar con conjuntos de sensores de medici√≥n y ofrecer mejoras en servicios gracias al procesamiento de la informaci√≥n recopilada.</p>
<p>En otro informe elaborado por el Centre of Regional Science de Viena (2) realiza una divisi√≥n de los problemas que puede abarcar una Smart City en seis grupos principales:</p>
<ul>
<li>Smart Economy: Abordan problemas de mejora de productividad que permiten aumentar la competitividad de las ciudades en cuanto al tema econ√≥mico se refiere.</li>
<li>Smart Governance: Solucionan problemas relacionados con servicios a ciudadanos, funcionamiento de administraciones y participaci√≥n pol√≠tica.</li>
<li>Smart Environment: Aborda los estudios de las condiciones naturales de una ciudad, midiendo aspectos medioambientales como el clima o la poluci√≥n.</li>
<li>Smart People: Cuando se emplean las TIC para desarrollar servicios de interacci√≥n social de los ciudadanos, as√≠ como las mejoras en servicios educativos.</li>
<li>Smart Mobility: Permiten mejorar las redes de transporte de las ciudades, ofreciendo un servicio inteligente de informaci√≥n de tr√°fico con el que se pueda controlar eficientemente el flujo de veh√≠culos por la zona urbana.</li>
<li>Smart Living: Engloba problemas relacionados con varios aspectos de la calidad de vida, como la cultura, salud, seguridad, turismo, etc‚Ä¶</li>
 </ul>
<img src="images/ilu1">Clasificaci√≥n de las Smart Cities del CRS de Viena</img>
<p>Varios estudios concluyen que en los pr√≥ximos a√±os el n√∫mero de personas que vivir√°n en zonas urbanas crecer√° considerablemente, por lo que la optimizaci√≥n de recursos de las ciudades resulta un problema que se ha de resolver con la mayor eficacia posible. El uso de las TIC y la conversi√≥n de las ciudades en Smart Cities puede ser la clave para conseguir dichas mejoras y hacer posible la convivencia de una poblaci√≥n mayor a la actual en espacios urbanos, siempre que estos alcancen un nivel de eficiencia y sostenibilidad suficiente.</p>
<h2>Smart Cities en Espa√±a</h2>
<p>Espa√±a es un pa√≠s que ha invertido enormemente en el uso de energ√≠as renovables y en desarrollo sostenible. De hecho, actualmente, las energ√≠as renovables cubren en torno al 14% del consumo total del pa√≠s (3), y tiene un plan de crecimiento de su uso en el que se ha marcado como objetivo cubrir el 20% para el a√±o 2020.</p>
<p>Para el uso eficiente de esta energ√≠a generada en espacios urbanos, es esencial la transformaci√≥n de ciudades en Smart Cities, y en Espa√±a tambi√©n hay una fuerte inversi√≥n en el uso de las TIC (4). Existen m√°s de 50 ciudades que conforman una red espa√±ola de ciudades inteligentes llamadas RECI, con el objetivo de, adem√°s de aprovechar al m√°ximo los recursos energ√©ticos, mejorar los servicios de estas ciudades y reducir el gasto p√∫blico, generando as√≠ progreso y atrayendo actividad econ√≥mica.</p>
<img src="images/ilu2">Mapa de ciudades que conforman la RECI</img>
<p>La Red Espa√±ola de Ciudades Inteligentes (5) divide sus actividades en cinco grupos de trabajo, seg√∫n el objetivo de las TIC implantadas:</p>
<ul>
<li>Innovaci√≥n Social: Trata mejoras en accesibilidad, cultura, participaci√≥n ciudadana, salud, seguridad y emergencias, turismo y ocio, educaci√≥n y gobierno abierto y open data.</li>
<li>Energ√≠a: Alberga problemas de informaci√≥n ciudadana sobre eficiencia energ√©tica y de instalaciones de energ√≠as renovables, alumbrado p√∫blico y edificios ‚Äúsmart space‚Äù.</li>
<li>Medio Ambiente, Infraestructuras y Habitabilidad Urbana: Para temas de calidad ambiental, sostenibilidad de edificios e infraestructuras p√∫blicas, gesti√≥n de parques y jardines p√∫blicos, recogida de residuos, medici√≥n de par√°metros ambientales y urbanismo.</li>
<li>Movilidad urbana: Con sistemas inteligentes de transportes y movilidad el√©ctrica.</li>
<li>Gobierno, Econom√≠a y Negocios: Que trata temas de administraci√≥n electr√≥nica, nuevos modelos de negocio, empleo, comercio electr√≥nico, CPDs virtuales y entornos cloud.</li>
</ul>
<h2>El proyecto Smart Santander</h2>
<p>Smart Santander (6) es una iniciativa para crear un banco de experimentos o testbed en el que se puedan desarrollar y probar aplicaciones y servicios para smart cities. Ofrece una interfaz de acceso a los datos que generan unos 20.000 sensores colocados a lo largo de las ciudades de Belgrado (Serbia), Guildford (Inglaterra), L√ºbeck (Alemania) y Santander (Espa√±a, con 12.000 sensores) que recogen medidas relacionadas con la movilidad urbana y el medio ambiente.</p> 
<img src="images/ilu3">Esquema de arquitectura del proyecto SmartSantander</img>
<p>La arquitectura del testbed comienza con la colocaci√≥n de una red de sensores y repetidores a lo largo de la ciudad, llamados nodos IoT, los cuales leen o repiten los par√°metros que generan los sensores utilizando el protocolo 802.15.4 de comunicaci√≥n de dispositivos de bajo consumo. </p>
<p>La informaci√≥n generada se env√≠a a varios gateways que funcionan a modo de puerta de comunicaci√≥n entre la infraestructura de sensores y los servidores centrales a los que se conectan los diferentes clientes a trav√©s de varias capas de servicios que se ofrecen: Autenticaci√≥n, soporte de experimentos, gesti√≥n del testbed y soporte de aplicaciones.</p>
<p>Actualmente existen varios experimentos que utilizan el testbed de SmartSantander como fuente de datos para probar las aplicaciones y herramientas que desarrollan. Entre ellos destacan los siguientes:</p>
<ul>
    <li>Mitos: Aplicaci√≥n para generar mapas de rutas entre varios puntos. Utiliza los datos de SmartSantander para a√±adir tambi√©n informaci√≥n en tiempo real de tr√°fico, aparcamientos y ruido. Ofrece tambi√©n un sistema de predicci√≥n de la mejor zona para aparcar en el momento.</li>
    <li>Smart Travel: Utilizando los datos de tr√°fico de SmartSantander, realiza una estimaci√≥n con un modelo de flujo de tr√°fico e informa de posibles puntos de congesti√≥n, para que el usuario pueda elegir la ruta m√°s eficiente hacia su destino.</li>
    <li>InterDataNet: Este experimento consiste en la elaboraci√≥n de una herramienta web para la monitorizaci√≥n de todos los sensores de la infraestructura IoT, mostrando las medidas de cada uno en un mapa de la ciudad.</li>
    <li>SEN2SOC: Pretende desarrollar una aplicaci√≥n m√≥vil en la que los usuarios puedan visualizar informaci√≥n y alertas sobre los datos le√≠dos por los sensores, as√≠ como eventos sociales de la ciudad recogidos mediante un an√°lisis de la informaci√≥n de redes sociales.</li>
</ul>
<h1>Desarrollo</h1>
<p>A continuaci√≥n se describe el proceso de desarrollo seguido para la elaboraci√≥n de la arquitectura Big Data del proyecto. Se comienza con una visi√≥n global del producto que se desea construir, para posteriormente ir desgranando en detalle cada uno de los elementos desarrollados y terminar finalmente con la visualizaci√≥n final de datos dise√±ada.</p>
<h2>Objetivos del proyecto</h2>
<p>El proyecto consiste en realizar un nuevo experimento con el testbed del proyecto SmartSantander, que recoja los datos que genera la infraestructura de sensores que compone la Smart City.</p>
<p>Se desea utilizar tecnolog√≠a Big Data para tratar toda esa informaci√≥n y generar varios an√°lisis avanzados de los datos recolectados.
Punto por punto, cada uno de los objetivos del proyecto son los que se describen a continuaci√≥n:</p>
<ul>
    <li>OBJ-01. En primer lugar, se realizar√° una visualizaci√≥n de informaci√≥n agregada de las diferentes medidas de los sensores en un mapa web. Este mapa debe ofrecer los distintos puntos donde se colocan los sensores, mostrando las medidas promedio en un intervalo de tiempo espec√≠fico seleccionado por el usuario para una magnitud tambi√©n elegida. En principio, se utilizar√° el cuarto de hora como intervalo de agregaci√≥n de datos.</li>
    <li>OBJ-02. Esta informaci√≥n se desea tener accesible lo m√°s r√°pido posible, por lo que tambi√©n se desea construir un proceso en tiempo real que vaya calculando los agregados de los intervalos temporales actuales, as√≠ como que se ofrezcan lo m√°s r√°pidamente posible a trav√©s de la interfaz web.</li>
    <li>OBJ-03. En segundo lugar, se desea realizar alg√∫n tipo de an√°lisis estad√≠stico avanzado de la informaci√≥n. Se va a dise√±ar un algoritmo de clustering que clasifique los d√≠as seg√∫n el comportamiento de una de sus medidas, concretamente la temperatura. Se debe construir adem√°s una interfaz web intuitiva con la que se puedan explorar los resultados de cada uno de los grupos generados, as√≠ como poder compararlos con las medidas de los d√≠as que hayan entrado en el proceso de c√°lculo.</li>
    <li>OBJ-04. Al ser un proyecto Big Data, se desea tambi√©n que los procesos de c√°lculo, almacenamiento y an√°lisis de la informaci√≥n sean escalables, de manera que se elija la tecnolog√≠a que mejor se adapte a cada una de las partes de la arquitectura que se dise√±e y se construya.</li>
    <li>OBJ-05. Finalmente, se prefiere utilizar herramientas de Big Data de uso en la actualidad y que no se hayan impartido en clase, con el fin de completar los conocimientos adquiridos con experiencia en otras tecnolog√≠as emergentes; como por ejemplo utilizar Apache Spark para procesamiento offline de la informaci√≥n.</li>
</ul>
<h2>Arquitectura de la soluci√≥n</h2>
<p>Para dise√±ar la arquitectura Big Data de la soluci√≥n, es necesario primero ir punto por punto de los objetivos y definir para cada uno de ellos las herramientas tecnol√≥gicas ideales para desarrollar dichas tareas.</p>
<p>Todos los objetivos anteriores requieren obtener previamente los datos emitidos por la arquitectura IoT del testbed de Santander, por lo que habr√° que a√±adir un objetivo secundario que comprende la adquisici√≥n y almacenamiento de datos emitidos por los sensores.
Para esta primera tarea de adquisici√≥n, es conveniente elaborar un estudio inicial de la informaci√≥n a recopilar. Se partir√° de una interfaz web que ya ofrece el equipo de SmartSantander en su p√°gina web con un mapa con los datos actuales de cada uno de los sensores, en cada una de las magnitudes que miden.</p>
<img src="images/ilu4">Interfaz web con acceso a los datos de sensores de SmartSantander</img>
<p>Para ayudar en la inserci√≥n, se desarrollar√° un proceso que leer√° cada cierto tiempo los datos de la web y los almacenar√°.</p>
<p>Este almac√©n de datos debe ser le√≠do posteriormente por un proceso que distribuya la informaci√≥n en un sistema de ficheros HDFS. Para llevar esa tarea, se almacenar√°n las lecturas en una cola Apache Kafka, ya que es una herramienta escalable que permite llevar un offset del mensaje que cada uno de los consumidores va leyendo, permitiendo interrumpir y continuar la carga donde se dej√≥ la √∫ltima vez. Dicho consumidor ser√° un agente Flume, que lea los mensajes, les pueda aplicar un tratamiento de limpieza y almacene finalmente las lecturas de manera distribuida y preparada para su acceso posterior por parte de cada una de las herramientas que se tengan que construir en cada uno de los objetivos indicados.</p>
<p>Para el objetivo OBJ-01 referente a la visualizaci√≥n de las medidas agregadas de cada uno de los sensores por cada cuarto de hora, se necesitar√° realizar un proceso offline de tratamiento de datos que agregue y almacene de manera accesible por la web la informaci√≥n de las lecturas de datos. Para ello se construir√° un job utilizando Apache Spark que lea los ficheros del HDFS y agregue la informaci√≥n para posteriormente almacenarla en una base de datos columnar que agilice el acceso a los datos desde la interfaz web. La base de datos elegida es Cassandra, que aporta unos tiempos de escritura bastante r√°pidos y permite la escalabilidad sin tener un punto √∫nico de fallo. Para acceder a esta base de datos por parte de la interfaz web, se construir√° una API REST utilizando Spring que reciba las peticiones de los usuarios y acceda a la base de datos de Cassandra, que tendr√° una tabla optimizada para cada una de las querys que la web necesite. La interfaz web se implementar√° utilizando ExtJS, junto con componentes HTML5 y JQuery que mostrar√°n los datos.</p>
<p>En cuanto al objetivo OBJ-02, en el que se pretende acceder en tiempo real al valor agregado actual de los datos de los sensores, se construir√° una topolog√≠a con Apache Storm que acceda directamente a la cola Kafka de recepci√≥n de los mensajes, limpie la informaci√≥n, la agregue en el cuarto de hora actual y la almacene en la misma tabla de la base de datos Cassandra donde la almacena el proceso batch descrito anteriormente. Ambos procesos convivir√≠an siguiendo el patr√≥n de arquitecturas lambda para el procesamiento offline y online de la informaci√≥n de un sistema Big Data.</p>
<p>Para realizar el objetivo OBJ-03, el desarrollo de un algoritmo de clustering que clasifique d√≠as en base a alguna de las magnitudes, se crear√° un nuevo job con Spark que recoja y agregue la informaci√≥n para despu√©s pasarla a un cl√∫ster K-Means utilizando la librer√≠a MLLib que implementa este mismo algoritmo de manera distribuida y escalable. El resultado de la ejecuci√≥n se almacenar√° tambi√©n en la misma base de datos Cassandra para que sea accesible a trav√©s de la API REST. Para determinar el n√∫mero de grupos √≥ptimo, se realizar√° previamente un estudio, observando la variaci√≥n de la suma de errores cuadr√°ticos en cada uno de los k valores posibles. La visualizaci√≥n de la informaci√≥n se realizar√° con una nueva webapp utilizando ExtJS que ataque a la API REST, al igual que en el OBJ-01.</p>
<p>Todos los componentes descritos anteriormente conforman la arquitectura de la soluci√≥n. En resumen, estos componentes son:</p>
<ul>
<li>Una aplicaci√≥n de web scrapping que recoja las fuentes</li>
<li>Una cola Kafka que reciba y almacene temporalmente las fuentes recibidas desde el web scrapper.</li>
<li>Un agente Flume que lea de la cola Kafka, realice un proceso de limpieza de la informaci√≥n y almacene los datos de manera distribuida.</li>
<li>Un sistema de ficheros HDFS que recibe los datos del agente Flume.</li>
<li><p>Un servidor Spark que se encargue del procesamiento batch, a priori de dos jobs:</p>
    <ul>
       <li>Un job encargado de la agregaci√≥n de la informaci√≥n.</li>
       <li>Un job que con MLLib calcule un algoritmo de clustering con los datos de una de las medidas.</li>
    </ul>
</li>
<li>Un servicio Storm que lea de la cola Kafka utilizando otro consumidor que no sea el del proceso Flume y que agregue la informaci√≥n de las mediciones actuales de los sensores.</li>
<li>Una base de datos Cassandra que almacene los resultados tanto de los jobs del servidor Spark como de la topolog√≠a del servicio Storm.</li>
<li>Una API REST hecha con Spring que sirva de interfaz entre peticiones de datos de usuarios externos y la base de datos Cassandra con los resultados de los procesos online y offline.</li>
<li><p>Un servidor Apache Tomcat de aplicaciones web en el que se publicar√°n dos p√°ginas de visualizaci√≥n de datos:</p>
    <ul>
        <li>Una p√°gina que dibuje en un mapa los datos de los sensores por cada medida y agregaci√≥n temporal calculada.</li>
        <li>Una p√°gina que muestre y permita interactuar con los resultados de la ejecuci√≥n del algoritmo de clustering.</li>
    </ul>
</li>
</ul>
<p>En resumen, la arquitectura software que se pretende construir presenta el siguiente esquema:</p>
<img src="images/ilu5">Arquitectura Software de la soluci√≥n</img>
<h2>Dise√±o de los elementos de la arquitectura</h2>
<p>Una vez construido el dise√±o general de la soluci√≥n Big Data, se ha procedido a dise√±ar y construir cada uno de los componentes que la forman. En este apartado se explican con detalle todos estos componentes, as√≠ como los problemas encontrados durante su implementaci√≥n.</p>
<h3>Proceso de web scrapping</h3>
<p>El proceso de web scrapping tiene b√°sicamente el objetivo de leer cada cierto intervalo de tiempo los datos de sensores de la web fuente y almacenarlos en una cola Kafka.</p>
<p>Para ello, se ha creado una aplicaci√≥n Java que recibe tres par√°metros:</p>
<ul>
<li>u: conjunto de urls, separadas por coma, de las que el proceso har√° scrapping.</li>
<li>i: intervalos de tiempo en segundos entre petici√≥n y petici√≥n.</li>
<li>k: direcci√≥n y puerto donde se localiza la cola Kafka en la cual se almacenar√°n las p√°ginas le√≠das.</li>
</ul>
<p>La aplicaci√≥n abrir√° un hilo de ejecuci√≥n por cada url que se pase por par√°metro. Cada hilo har√° una petici√≥n de descarga de contenido a su url espec√≠fica cada cierto tiempo, determinado por el par√°metro de intervalo, almacen√°ndolo posteriormente en la cola Kafka.</p>
<p>Para marcar el tiempo en el que un contenido fue descargado, se incluye al inicio de cada mensaje que ir√° a la cola Kafka la fecha y hora en la que fue descargado, separado posteriormente con el car√°cter ‚Äò~‚Äô, de manera que en procesos posteriores de limpieza de los mensajes se pueda extraer y utilizar.</p>
<p>Esta aplicaci√≥n se ha hecho gen√©rica, para que pueda ser utilizada no solo con el proyecto SmartSantander, sino en otros en los que se requiera realizar un web scrapping que almacene el contenido le√≠do en una cola Kafka.</p>
<p>El c√≥digo de la aplicaci√≥n se encuentra bajo la carpeta ssscrapper y se ha hecho utilizando Eclipse y Maven para gestionar las dependencias de librer√≠as Java.</p>
<p>Contiene principalmente dos clases localizadas en el mismo paquete (com.utad.pebd.marcosgarciacasado.ssscrapper):</p>
<ul>
<li>SSScrapper: Clase principal a la que se debe de llamar. Se encarga de parsear los argumentos y lanzar los hilos de ejecuci√≥n para cada url de descarga.</li>
<li>URLPeriodicDownload: Clase runnable que descarga cada cierto periodo de tiempo el contenido de la url asociada a una cola Kafka.</li>
</ul>
<p>Para interrumpir la descarga es necesario matar el proceso, puesto que cada uno de los hilos ejecuta un bucle infinito de peticiones en cada intervalo temporal.</p>
<p>En este proyecto en espec√≠fico, se debe leer de un mapa web localizado en la url maps.smartsantander.eu. Se deben descargar los datos de dos mapas diferentes: el del apartado IoT Infraestructure, en el que se encuentran los sensores fijos de la red de Santander, y el mapa del apartado Mobile Sensing, que contiene las mediciones de los sensores wireless instalados en unidades m√≥viles como taxis o autobuses.</p>
<p>Analizando el c√≥digo de esta p√°gina web, se puede apreciar que estos mapas cargan sus datos desde dos scripts php que devuelven un objeto JSON con una cierta estructura. Dichos scripts se llaman getdata.php (para el mapa IoT Infraestructure) y getdatatus.php (para el mapa Mobile Sensing).</p>
<p>Cada elemento del objeto JSON corresponde con los datos de un sensor, que puede tener varias mediciones de distintas magnitudes, dependiendo de su tipo. Estas mediciones vienen encapsuladas en c√≥digo HTML correspondiente con el popup que se muestra cuando se hace click en un marcador de sensor del mapa. En posteriores pasos se procede a analizar dicho HTML y extraer la medici√≥n de cada magnitud.</p>
<p>Para la parte de almacenamiento, se ha instalado una cola Kafka y se ha creado un nuevo t√≥pico llamado ‚Äússda‚Äù donde se almacenar√°n todos estos mensajes producidos por el web scrapper.</p>
<p>En cuanto al n√∫mero de segundos de intervalo, se ha decidido utilizar 15 segundos, ya que se prev√© de esta manera obtener casi todas las actualizaciones de mediciones de datos. Cada descarga de los objetos JSON ocupa 1MB aproximadamente, por lo que se puede estimar la cantidad de informaci√≥n que se almacenar√° diariamente en la cola Kafka:</p>
<p>(1MB/intervalo * 60 segundos/minuto * 60 minutos/hora * 24 horas/d√≠a) / 15 segundos/intervalo = 5.62 GB/d√≠a</p>
<p>La cola Kafka se ha configurado para que almacene los √∫ltimos 5 d√≠as con un factor de replicaci√≥n de 1, por lo que el  tama√±o necesario para almacenarla es aproximadamente de 28.1 GB.</p>
<p>La llamada al proceso por lo tanto tendr√° que hacerse una vez arrancada la cola Kafka y con los siguientes par√°metros:</p>
<ul>
<li>u: maps.smartsantander.eu/getdata.php, maps.smartsantander.eu/getdata.php</li>
<li>i: 15</li>
<li>k: localhost:2181</li>
</ul>
<h3>Proceso de ingesti√≥n de datos y almacenamiento</h3>
<p>Una vez se tenga la informaci√≥n almacenada en la cola Kafka, el siguiente paso es el de leer dicha cola y almacenarla en un sistema de ficheros distribuido como HDFS. Para ello se ha utilizado Apache Flume, en el que un agente leer√° como consumidor de mensajes la cola ‚Äússda‚Äù de Kafka, realizar√° un tratamiento de limpieza de los objetos JSON para extraer los valores de las magnitudes le√≠das por sensor. Finalmente, se ha configurado un sink HDFS para almacenar los datos en varios ficheros cuyo formato se describe posteriormente en este apartado.</p>
<h4>Source</h4>
<p>El Source que se ha de configurar en el agente Flume debe ser capaz de leer los mensajes de una cola Kafka. En la instalaci√≥n inicial de Flumen no se encuentra ese elemento, por lo que se ha descargado y a√±adido uno diferente, localizado en github.com/baniuyao/flume-ng-kafka-source. Este artefacto es compatible con la versi√≥n 0.7.2 de Kafka y no con las versiones actuales 0.8.1, por lo que se ha tenido que estudiar el c√≥digo y refactorizar las peticiones del consumidor Kafka para que se pueda utilizar con nuevas versiones.</p>
<p>Por otro lado, no se pretende almacenar los mensajes fuente tal y como se descargan, sino reestructurar los objetos JSON le√≠dos de manera que se pueda extraer del contenido HTML que cada uno de ellos tiene los valores de cada una de las magnitudes de los sensores. Para ello, se ha construido un interceptor personalizado que se encarga de reformatear los objetos JSON antes de almacenarlos en HDFS. El c√≥digo del proyecto Eclipse de este interceptor se encuentra en la carpeta ssjsonformatterinteceptor.</p>
<p>Por cada mensaje, se tiene por un lado la fecha en la que fue descargado de la web, a√±adida directamente en el web scrapper, seguido de un array JSON en el que cada elemento es una lectura de un sensor completo. Este objeto JSON tiene la siguiente estructura:</p>
<ul>
<li>id: c√≥digo de identificaci√≥n del sensor dentro de la red IoT</li>
<li>latitude: latitud de la posici√≥n del sensor</li>
<li>longitude: longitud de la posici√≥n del sensor</li>
<li>title: nombre del sensor</li>
<li>image: url al icono del marcador del sensor en el mapa web</li>
<li>content: contenido HTML del popup del marcador, en el que se encuentran los valores de todas las magnitudes que el sensor mide en el momento de la extracci√≥n</li>
<li>tags: tipo de sensor</li>
</ul>
<p>Por cada tag o tipo de sensor, se tienen diferentes magnitudes de las que se puede extraer su valor. El interceptor lo que hace por lo tanto es leer el tag y extraer unas medidas u otras dependiendo de su valor. Una vez se pasa un objeto JSON por el interceptor, queda de la siguiente manera:</p>
<ul>
<li>tags: tipo de sensor
<li>latitude: latitud de la posici√≥n del sensor
<li>longitude: longitud de la posici√≥n del sensor
<li>title: nombre del sensor
<li>id: c√≥digo de identificaci√≥n del sensor dentro de la red IoT
<li>last-update ultima fecha de actualizaci√≥n de la informaci√≥n del sensor. Esta fecha puede aparecer o no, dependiendo del tipo de sensor.
<li>battery: nivel de energ√≠a del sensor
<li>requesttime: fecha y hora de la descarga de la medici√≥n
<li><p>medidas: al mismo nivel que el resto, aparecen diferentes magnitudes que los sensores ofrecen. Estas magnitudes pueden ser de los siguientes tipos:</p>
<ul>
    <li>humidity: porcentaje de humedad del aire.</li>
    <li>altitude: altitud sobre el nivel del mar en metros.</li>
    <li>wind-speed: velocidad del viento en km/h.</li>
    <li>soil-moisture: cantidad de agua en tierra.</li>
    <li>noise: nivel de ruido en decibelios.</li>
    <li>co-index: nivel de CO2 en el aire.</li>
    <li>parking: porcentaje de espacio de aparcamiento libre.</li>
    <li>odometer: kil√≥metros recorridos por el medio de transporte del sensor.</li>
    <li>speed: velocidad en km/h.</li>
    <li>temperatura: temperatura en grados Celsius.</li>
    <li>atmospheric-pressure: presi√≥n atomosf√©rica.</li>
    <li>soil-temperature: temperatura del suelo.</li>
    <li>count: conteo de veh√≠culos en tr√°nsito.</li>
    <li>occupancy: cantidad de plazas ocupadas en el medio de transporte</li>
    <li>rainfall: nivel de precipitaciones.</li>
    <li>solar-radiation: radiaci√≥n solar.</li>
    <li>luminosity: porcentaje de luminosidad</li>
    <li>relative-humidity: porcentaje de humedad relativa del aire</li>
</ul>
</li>
</ul>
<p>Adem√°s de formatear los mensajes JSON, el interceptor se encarga tambi√©n de reducir el espacio utilizado, almacenando √∫nicamente aquellas mediciones que han variado; evitando insertar informaci√≥n duplicada. Para ello mantiene una tabla hash en la que la clave es el campo title de cada sensor y el valor es el c√≥digo hash de la concatenaci√≥n del campo content con el campo image. Cuando viene un nuevo mensaje, se comprueba si el sensor se encuentra en la tabla hash y si el hashcode del contenido coincide con el almacenado. En caso de ser verdad, se descarta el mensaje; y si en cambio es falso, se a√±ade el nuevo c√≥digo hash a la tabla y se procesa y almacena el mensaje entrante.</p>
<p>Gracias a esta modificaci√≥n que controla si el dato ha variado o no, se ha reducido considerablemente la cantidad de informaci√≥n que se almacena. Tras ejecutar las pruebas necesarias para medir el almacenamiento que genera el proceso de ingesti√≥n, se pasa de necesitar una cantidad de almacenamiento similar a la de los mensajes originales, unos 5.6 GB al d√≠a, a necesitar simplemente 50 MB por d√≠a (un 99% menos).</p>
<h4>Channel</h4>
<p>El proceso no recibe datos a una velocidad problem√°tica como para quedarse sin memoria en alg√∫n momento, por lo que el canal configurado es de tipo in-memory, permitiendo una velocidad mayor que si se configura para que los mensajes se guarden en disco persistente.</p>
<h4>Sink</h4>
<p>El sink del agente env√≠a los mensajes al sistema de almacenamiento HDFS. Para cerrar ficheros frecuentemente y no tener la posibilidad de perder mucha informaci√≥n en el caso de que el proceso de ingesti√≥n falle, el sink est√° configurado para escribir en ficheros nuevos cada 15 minutos. Estos ficheros se clasifican tambi√©n en carpetas, teniendo una por a√±o y dentro de ellas, una por cada mes.</p>
<p>El formato de almacenamiento permite que en alg√∫n momento se pueda crear una tabla externa con Hive con la que hacer querys r√°pidamente a todos los ficheros, utilizando el JSON SerDe como parser.</p>
<p>Como ya se indic√≥ anteriormente, cada d√≠a se almacenan alrededor de 50MB de informaci√≥n de sensores. Con un factor de replicaci√≥n 3, esto aumenta a 150MB, con lo que el crecimiento de los datos mensual ser√≠a de aproximadamente 4.4GB. </p>
<p>Inicialmente no es un problema Big Data en cuanto a la volumetr√≠a de la informaci√≥n a tratar, pero el proceso est√° preparado para a√±adir m√°s informaci√≥n, ya sea por el crecimiento temporal indicado o por la inclusi√≥n de nuevos sensores o de nuevas ciudades en el almac√©n.</p>
<h3>Procesamiento batch de tratamiento de la informaci√≥n</h3>
<p>El proceso batch que se ha desarrollado trata de agregar la informaci√≥n almacenada en HDFS y guardarla en una base de datos Cassandra. El c√≥digo de este paso se encuentra en la carpeta ssbatch. Es un proyecto Eclipse que utiliza Maven y est√° codificado en Scala.</p>
<h4>Elecci√≥n de herramientas de procesamiento</h4>
<p>Para los procesos offline que se han construido, se ha decidido utilizar Spark, ya que es una herramienta emergente que aspira a sustituir a MapReduce, al poder controlar el almacenamiento en memoria o en disco de las estructuras de datos distribuidos, llamados RDDs, ofreciendo una velocidad mayor puesto que ahorra accesos a memoria persistente.</p>
<p>En cuanto a la codificaci√≥n de los jobs, se ha elegido utilizar Scala, un lenguaje sencillo que puede importar librer√≠as Java y que tiene su propia API Spark.</p>
<p>Para conectar la base de datos Cassandra con Spark se ha utilizado el plugin cassandra-spark de la empresa Datastax con el que se puede almacenar directamente un RDD a una tabla de forma distribuida.</p>
<h4>Filtro de datos espurios</h4>
<p>El primer job que se ha desarrollado se llama SSEstimateCI. Se encarga de realizar un filtro de los datos, con el fin de descartar para el c√°lculo de los agregados aquellas mediciones que puedan ser err√≥neas. Para ello, se ha hecho un job auxiliar que calcule la media y la desviaci√≥n t√≠pica de cada una de las magnitudes. Estas medias y desviaciones se almacenan en una tabla de la base de datos Cassandra (la tabla ssda.ss_measures_stats).</p>
<p>Para calcular la media, se recoge en una fase map los pares medida y valor. En la fase combine/reduce se suman los valores por un lado y se cuenta la cantidad de estos por otro. Para extraer la media, se divide la suma por el conteo final.</p>
<p>Para la desviaci√≥n t√≠pica, se utilizan las medias calculadas previamente para medir en una fase map la distancia de cada valor a esta. Se suman estas potencias al cuadrado en una fase reduce, junto con el conteo de los valores que hay y para extraer el resultado se divide la suma de potencias por la cantidad de valores menos 1 y despu√©s se extrae su ra√≠z cuadrada.</p>
<h4>Agregado de valores filtrados</h4>
<p>Este job es el proceso de agregado inicial. Se llama SSBatchProcess. Utiliza el resultado del job previo SSEstimateCI, por lo que es necesario que este se ejecute antes.</p>
<p>Cada elemento que lee el job es un conjunto de mediciones de un sensor. Queremos guardar un dato por cada medida, por lo que lo primero que se hace es ejecutar un flatMap en el que se emitan tantas filas por sensor como valores muestre. Para las medidas que salgan de cada sensor, se mapean para obtener pares clave valor (k, v), en los que k ser√° la combinaci√≥n de la latitud, la longitud  y el cuarto de hora en el que entre la fecha de recogida del dato; y como valor la magnitud y su valor medido.</p>
<p>A continuaci√≥n, se leen de Cassandra la media y la desviaci√≥n t√≠pica de cada medida, almacen√°ndolos en un HashMap para poder aplicar a continuaci√≥n un filtro de datos espurios. En un map que recorra los datos, los valores que sumen al agregado son aquellos que se encuentren en el intervalo ùúá‚àí2ùúé, ùúá+2ùúé, siendo ¬µ la media y œÉ la desviaci√≥n t√≠pica.</p>
<p>Con los datos filtrados se procede a agrupar los pares clave valor para calcular el agregado. Se calcula la media, por lo que en la agregaci√≥n se recoge por un lado la suma de los valores y por otro el conteo. Finalmente, para obtener la media se realizar√≠a una divisi√≥n entre ellos.</p>
<p>Una vez se tiene el agregado calculado, se almacena en la base de datos de Cassandra. La tabla destino se llama ss_measures_agr y tiene los campos measure, time, latitude, longitude y value. La Row Key es (measure, time) para optimizar la consulta de las mediciones de una magnitud en un cuarto de hora concreto.</p>
<p>Tambi√©n se guarda posteriormente en otra tabla llamada ss_measures_ts_agr con los mismos campos, pero esta vez la rowkey es measure, latitude y longitude; de manera que se puedan sacar de forma √≥ptima series temporales con el hist√≥rico de medici√≥n de la medida elegida en las coordenadas seleccionadas.</p>
<h3>Procesamiento real-time de tratamiento de la informaci√≥n</h3>
<p>El proceso real-time realiza el mismo c√°lculo que el proceso batch de c√°lculos de agregado, con la diferencia de que lee de la cola Kafka de mensajes directamente y escribe en Cassandra el agregado del cuarto de hora actual, actualiz√°ndolo cada vez que cambia la informaci√≥n. El decalaje de tiempo entre que cambia el dato y se muestra en la visualizaci√≥n es simplemente el tiempo que tarda en ser recogido por el web-scrapper, el tiempo que tarde la cola Kafka en leer el mensaje del productor y envi√°rselo al consumidor, y el tiempo que tarde el proceso real-time en agregar la informaci√≥n y almacenarla en las tablas de Cassandra de las que se alimenta el visor web.</p>
<h4>Elecci√≥n de herramientas de procesamiento</h4>
<p>La herramienta elegida para implementar este servicio ha sido Storm, ya que permite aumentar f√°cilmente el n√∫mero de nodos de c√≥mputo y por otro lado asegura que todos los mensajes lleguen a ser procesados.</p>
<p>Se ha dise√±ado e implementado una topolog√≠a en la que cada uno de los pasos tiene una tarea sencilla y que en conjunto realizan todo el trabajo que se desea.</p>
<h4>Topolog√≠a</h4>
<p>La topolog√≠a que se ha dise√±ado consta de 5 capas: 1 capa de spouts y 4 de bolts. Todas se comunican secuencialmente, habiendo un √∫nico camino en el tr√°nsito de los datos:</p>
<img src="images/ilu6">Esquema de topolog√≠a del proceso Storm</img>
<p>Las cinco capas de la topolog√≠a son las siguientes:</p>
<ul>
<li>KafkaSpout: Conector de Kafka que introduce los mensajes de la cola con el t√≥pico ‚Äússda‚Äù a la red de procesos de la topolog√≠a Storm. Este spout lo ofrece Apache Storm, su dependencia Maven se llama storm-kafka.</li>
<li>JsonFormatterBolt: El JsonFormatterBolt recibe como librer√≠a el interceptor que se hizo para el proceso Flume de ingesti√≥n de datos y utiliza la funci√≥n para formatear el mensaje con las medidas de los sensores a un objeto JSON, con el fin de que en el resto de pasos se puedan leer sus valores.</li>
<li>MeasureFlattenerBolt: Este bolt se encarga de recoger cada uno de los JSON formateados previamente y emitir varios mensajes, uno por cada medida. De esta manera, cada mensaje emitido por esta capa tiene un valor de una medida correspondiente.</li>
<li>ContinuousAggregatorBolt: Recibe los mensajes de cada medida obtenida y realiza el agregado. Para ello, gestiona en una tabla hash la suma parcial que va obteniendo, reseteando los valores a cero cada vez que pasa un cuarto de hora. Como cada nodo tiene un agregado, no puede haber dos en los que vaya calculando las mismas medidas, por lo que hay que dirigir el tr√°fico de cada magnitud a un nodo en concreto de esta capa (sharding). Como resultado, env√≠a la media actual del valor que el mensaje haya actualizado.</li>
<li>CassandraSaveBolt: Este √∫ltimo paso se encarga simplemente de preparar una query de inserci√≥n en la base de datos Cassandra, concretamente en la tabla ss_measures_agr, e insertar el valor recibido del actual cuarto de hora.</li>
</ul>
<p>Al guardar los datos agregados en la misma tabla que lo guardaba el proceso batch, se integran autom√°ticamente ambos resultados y es transparente para el usuario el funcionamiento interno del proceso de actualizaci√≥n de la informaci√≥n que ve. Este patr√≥n de integraci√≥n de la parte de tiempo real con la parte offline es lo que se conoce como arquitectura lambda.</p>
<h3>Proceso de c√°lculo de cl√∫ster</h3>
<p>El objetivo del proceso de cl√∫ster es el de lanzar un algoritmo de clustering para clasificar los d√≠as en los que se tenga datos en varios grupos, de manera que los d√≠as de un grupo tengan una distribuci√≥n parecida de valores de la magnitud estudiada por cada cuarto de hora. Se ha escogido la temperatura como magnitud para realizar el estudio.</p>
<h4>Elecci√≥n de la herramienta de c√°lculo anal√≠tico a utilizar</h4>
<p>Se ha optado por utilizar la librer√≠a MLLib de Spark, ya que tiene un algoritmo para calcular de manera distribuida el cl√∫ster, pudiendo tener los datos de entrada en un RDD distribuido a lo largo del cl√∫ster. La ventaja de esto es que el c√°lculo tambi√©n ser√≠a escalable, reduci√©ndose proporcionalmente el tiempo de ejecuci√≥n a medida que se a√±aden nodos al cl√∫ster de Spark.</p>
<h4>Definici√≥n de variables</h4>
<p>El primer paso para desarrollar el algoritmo consiste en definir las variables del modelo, las cuales ser√°n la media de las temperaturas de los sensores por cada cuarto de hora. En total se tienen 96 variables diferentes, una por cada cuarto de hora que tiene un d√≠a completo. Cada elemento a clasificar se definir√° por la fecha en la que se extrajeron esas magnitudes, sin hora.</p>
<p>Finalmente hay que escoger el n√∫mero de clusters o agrupaciones en las que se van a clasificar los d√≠as. Para ello, se hace un primer lanzamiento de varios c√°lculos en los que cada uno tendr√° como par√°metro un n√∫mero de clusters diferentes. Se ha ejecutado de 2 a 7 grupos. Lo que se extrae es el error cuadr√°tico del modelo para cada lanzamiento, con el fin de mostrar cada uno de los valores en un gr√°fico. Se espera que el gr√°fico tenga una pendiente descendente y que en un momento se observe un cambio de tendencia en el que el error comience a converger a un valor. En ese punto es en el que habr√° que escoger el n√∫mero de agrupaciones para el lanzamiento del cl√∫ster final.</p>
<img src="images/ilu7">Gr√°fico de valores de errores cuadr√°ticos</img>
<p>En el momento que se realiz√≥ el estudio para el c√°lculo del n√∫mero √≥ptimo de clusters, solo se ten√≠an siete d√≠as completamente rellenos con datos, por lo que el gr√°fico desciende hasta error 0 cuando se llega a 7 grupos. Se ha decidido coger 6 como n√∫mero de grupos de momento, pero es conveniente volver a buscar el n√∫mero √≥ptimo de grupos cuando se tenga m√°s d√≠as almacenados en el HDFS. No obstante, ya se va observando un cambio de tendencia al ser la pendiente menos decreciente con m√°s grupos.</p>
<h4>Construcci√≥n del job para el lanzamiento del cl√∫ster</h4>
<p>El c√≥digo fuente del proceso Spark de clustering est√° en el fichero SSClusterCalc.scala en el proyecto ssbatch.</p>
<p>Para preparar los datos antes del lanzamiento de la funci√≥n de c√°lculo, se recogen del HDFS, al igual que en el proceso de agregaci√≥n de datos, se filtran para recoger √∫nicamente los datos de temperatura y se agrupa una primera vez de la misma manera. El valor del agregado se encapsula posteriormente en un objeto de tipo ClusterValue (un par cuarto de hora - valor) y se pasa de nuevo por un paso de agregaci√≥n, esta vez agrupando los valores por d√≠as y utilizando la funci√≥n groupByKey de Spark. De esta manera, se tiene para cada clave (d√≠a)  se tiene un array de objetos de tipo ClusterValue, en el que dentro se encuentra el cuarto de hora y el valor de la media de temperatura. Ese array se ordena por el valor del cuarto de hora y se convierte en un Vector de n√∫meros reales, que sirve de formato de entrada para el cl√∫ster.</p>
<p>Una vez que se han preparado los datos para la entrada del cl√∫ster, un RDD de vectores de reales, se ejecuta. Para ello se llama a la librer√≠a MLLib, concretamente a la creaci√≥n de un cl√∫ster KMeans con 6 grupos, 20 iteraciones de entrenamiento y el RDD formateado con los valores como entrada.</p>
<p>Una vez entrenado el modelo, se inserta en la base de datos Cassandra tanto la asociaci√≥n de cada d√≠a en su cl√∫ster, en la tabla ss_cluster_res, como los centroides de cada grupo, en la tabla ss_cluster_centers.</p>
<p>Estas dos tablas son las que leer√° la aplicaci√≥n web posteriormente y con la que rellenar√° la visualizaci√≥n.</p>
<h3>Sistema de acceso REST a la informaci√≥n</h3>
<p>Para acceder a los datos desde puntos externos, se ha desarrollado una API REST para que sea utilizada posteriormente por las aplicaciones web u otras futuras que se desarrollen y que requieran consultar datos resultantes del tratamiento de datos realizado.</p>
<p>La herramienta que se ha decidido utilizar ha sido el framework Spring para hacer servicios REST. Este servicio recibe peticiones GET desde interfaces externas que normalmente corresponden con una query a la base de datos Cassandra y devuelve objetos JSON con los datos resultantes.</p>
<p>El c√≥digo de esta secci√≥n del proyecto se encuentra en la carpeta ssdataaccess y es un proyecto Gradle desarrollado con Eclipse. Los servicios implementados hasta ahora son los siguientes:</p>
<ul>
<li>measuremap: dado un cuarto de hora de un d√≠a en concreto y una magnitud, devuelve los valores calculados para cada coordenada.</li>
<li>measurestats: devuelve la media y la desviaci√≥n t√≠pica calculada de cada una de las magnitudes.</li>
<li>clusterresults: devuelve el conjunto de d√≠as que se han calculado en el proceso de clustering, junto con el identificador del grupo en el que se han clasificado.</li>
<li>clustercenter: devuelve los valores de los centroides de un cl√∫ster, cuyo identificador se pasa por par√°metro. Los devuelve en forma de array de n√∫meros reales.</li>
<li>dayresults: dado un d√≠a y la magnitud, devuelve el conjunto de valores de cada cuarto de hora, como un array de n√∫meros reales.</li>
</ul>
<h2>Visualizaci√≥n de resultados</h2>
<p>En este apartado se describen las interfaces de visualizaci√≥n de datos generadas, tanto las medidas agregadas que se han calculado como la visualizaci√≥n de los resultados del cl√∫ster.</p>
<p>Para construir ambas visualizaciones se ha utilizado el framework ExtJs de creaci√≥n de aplicaciones web en Javascript, y se han colocado en el mismo servidor Tomcat que el servidor de la API REST de acceso a datos. Esto es esencial, ya que las peticiones se hacen a trav√©s de Ajax y no funciona dicho acceso a datos si no se encuentra bajo el mismo dominio y puerto.</p>
<h3>Visualizaci√≥n de medidas agregadas</h3>
<p>Para visualizar las medidas agregadas se ha pensado construir un mapa donde se pinten con marcadores los sensores con informaci√≥n de una magnitud elegida a trav√©s de un combobox, en un cuarto de hora dado escogido en un selector de fecha y hora.</p>
<p>Estos marcadores se posicionan en el mapa dadas las coordenadas del sensor y al hacer click muestra el valor de la medida seleccionada. Adem√°s, los marcadores var√≠an de color, de colores m√°s fr√≠os a m√°s c√°lidos, seg√∫n su valor dentro del rango marcado por la media y la desviaci√≥n t√≠pica que se us√≥ para calcular los filtros de datos espurios ùúá‚àí2ùúé, ùúá+2ùúé.</p>
<img src="images/ilu8">Visualizaci√≥n de datos agregados en el mapa de Santander</img>
<p>Para hacer el mapa se ha utilizado el servicio gratuito Mapbox, en el que se pueden guardar mapas personalizados. Utilizando su API para Javascript se han a√±adido los marcadores, que forman parte de la librer√≠a Leaflet.js de elementos de visualizaci√≥n de datos en mapas para JS.</p>
<h3>Visualizaci√≥n de resultados del cl√∫ster</h3>
<p>La otra visualizaci√≥n desarrollada es la de los resultados de la ejecuci√≥n del clustering de clasificaci√≥n de d√≠as por temperatura. Esta interfaz presenta en la parte izquierda superior los grupos de clasificaci√≥n de d√≠as, pintados cada uno con un color asociativo. Debajo de los grupos se muestra un calendario en el que se encuentran coloreados los d√≠as que han entrado en el estudio. El color de cada uno de los d√≠as es el mismo que el del cl√∫ster al que ha sido asociado, con lo que se intenta conseguir un efecto de mapa de calor de los d√≠as estudiados.</p>
<img src="images/ilu9">Visualizaci√≥n interactiva de los resultados del algoritmo de clustering</img>
<p>En el panel central de la aplicaci√≥n web se tiene un gr√°fico, hecho con la librer√≠a Highcharts, en el que poder ver la comparativa entre los valores de los centroides de los cl√∫ster (seleccionables estos a trav√©s del panel anterior) y el valor medio de los cuartos de hora de un d√≠a, tambi√©n seleccionable desde el calendario.</p>
<p>Con esta interfaz, el usuario puede interactuar con los d√≠as y analizar las caracter√≠sticas del resultado de cada grupo, para luego catalogarlos: grupo de d√≠as c√°lidos, de d√≠as de fr√≠o‚Ä¶ Adem√°s, puede sacar conclusiones en cuanto al cambio del tiempo con el paso de los d√≠as gracias a la visualizaci√≥n del calendario.</p>
    </body>
</html>
