<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta name="author" content="Marcos GarcÃ­a Casado" />
		<meta name="description" content="Smart Santander Data Analysis" />
		<meta name="keywords"  content="santander, smartsantander, data, big data, utad, marcosgarciacasado, marcos garcia" />
        <title>Smart Santander Data Analysis - Arquitectura</title>
        <!-- Bootstrap core CSS -->
        <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script> 
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
        <!-- Custom styles for this template -->
        <link href="stylesheets/carousel.css" rel="stylesheet">
        <style>
        .goToTop {
  position: fixed;
  top: 0;
  height: 70px;
  z-index: 1;
}
        </style>
    </head>

    <body>

<!-- box1 -->
<div id="box1" class="home">
  <div class="text-vcenter">
    <h1>Smart Santander Data Analysis - Arquitectura</h1>
 </div>
</div>
<!-- /box1 --> 

<!-- navbar -->
<nav class="navbar navbar-default" role="navigation">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar-collapse-main"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button>
      <a class="navbar-brand" href="#"></a> </div>
    <div class="collapse navbar-collapse" id="navbar-collapse-main">
      <ul class="nav navbar-nav navbar-right">
        <li><a href="javascript:void(0);">Home</a></li>
        <li><a href="javascript:void(0);">Menu Item #2</a></li>
        <li><a href="javascript:void(0);">Menu Item #3</a></li>
        <li><a href="javascript:void(0);">Menu Item #4</a></li>
        <li><ul class="nav navbar-nav navbar-right">
        <li><a href="javascript:void(0);">Home</a></li>
        <li><a href="javascript:void(0);">Menu Item #2</a></li>
        <li><a href="javascript:void(0);">Menu Item #3</a></li>
        <li><a href="javascript:void(0);">Menu Item #4</a></li>
        <li><a href="javascript:void(0);">Menu Item #5</a></li>
      </ul></li>
      </ul>
    </div>
  </div>
</nav>
<!-- /navbar --> 

<!-- box2 -->
<div id="box2" class="pad-section">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <h1>Antecedentes</h1>
<p>En este apartado se habla del estado del arte de las Smart Cities y del proyecto SmartSantander en concreto, desde el cual se recogen los datos de los sensores de la ciudad de Santander, y que se utilizan como fuentes de informaciÃ³n para su posterior tratamiento en la arquitectura Big Data desarrollada.</p>
<h2>Smart City</h2>
<p>Existen varias definiciones de lo que significa una Smart City, aunque todas concluyen en que es el empleo de las TecnologÃ­as de la InformaciÃ³n y de la ComunicaciÃ³n, conocidas como TIC, para ofrecer servicios de informaciÃ³n a nivel de zona urbana que permitan una mejora de ciertos elementos caracterÃ­sticos de una ciudad, como pueden ser los servicios pÃºblicos, la sostenibilidad o la eficiencia de uso de sus recursos; e incluso suponer un impulso econÃ³mico importante para la ciudad.</p>
<p>Este tÃ©rmino se ha llevado usando desde hace mÃ¡s de veinte aÃ±os. ComenzÃ³ usÃ¡ndose con fines energÃ©ticos: monitorizar ciertos elementos que permitan optimizar el consumo de energÃ­a de una ciudad y conseguir un ahorro econÃ³mico y una mejora en su sostenibilidad (1).</p>
<p>Pero con el paso de los aÃ±os se han comenzado a utilizar las TIC para otros fines, como son ayudas para mejorar el transporte y en el trÃ¡fico de vehÃ­culos en las ciudades, optimizaciÃ³n de sistemas de climatizaciÃ³n, construcciÃ³n de edificios sostenibles, gobernanza y gestiÃ³n de administracionesâ€¦</p>
<p>TelefÃ³nica (1) describe las Smart Cities como aquellas ciudades que utilizan las TIC para dotar a sus infraestructuras de herramientas que permitan la interacciÃ³n del ciudadano con los elementos urbanos. La considera como una plataforma en la que muchos agentes de distintos tipos pueden interactuar con conjuntos de sensores de mediciÃ³n y ofrecer mejoras en servicios gracias al procesamiento de la informaciÃ³n recopilada.</p>
<p>En otro informe elaborado por el Centre of Regional Science de Viena (2) realiza una divisiÃ³n de los problemas que puede abarcar una Smart City en seis grupos principales:</p>
<ul>
<li>Smart Economy: Abordan problemas de mejora de productividad que permiten aumentar la competitividad de las ciudades en cuanto al tema econÃ³mico se refiere.</li>
<li>Smart Governance: Solucionan problemas relacionados con servicios a ciudadanos, funcionamiento de administraciones y participaciÃ³n polÃ­tica.</li>
<li>Smart Environment: Aborda los estudios de las condiciones naturales de una ciudad, midiendo aspectos medioambientales como el clima o la poluciÃ³n.</li>
<li>Smart People: Cuando se emplean las TIC para desarrollar servicios de interacciÃ³n social de los ciudadanos, asÃ­ como las mejoras en servicios educativos.</li>
<li>Smart Mobility: Permiten mejorar las redes de transporte de las ciudades, ofreciendo un servicio inteligente de informaciÃ³n de trÃ¡fico con el que se pueda controlar eficientemente el flujo de vehÃ­culos por la zona urbana.</li>
<li>Smart Living: Engloba problemas relacionados con varios aspectos de la calidad de vida, como la cultura, salud, seguridad, turismo, etcâ€¦</li>
 </ul>
<img src="images/ilu1.png" alt="ClasificaciÃ³n de las Smart Cities del CRS de Viena"></img>
<p>Varios estudios concluyen que en los prÃ³ximos aÃ±os el nÃºmero de personas que vivirÃ¡n en zonas urbanas crecerÃ¡ considerablemente, por lo que la optimizaciÃ³n de recursos de las ciudades resulta un problema que se ha de resolver con la mayor eficacia posible. El uso de las TIC y la conversiÃ³n de las ciudades en Smart Cities puede ser la clave para conseguir dichas mejoras y hacer posible la convivencia de una poblaciÃ³n mayor a la actual en espacios urbanos, siempre que estos alcancen un nivel de eficiencia y sostenibilidad suficiente.</p>
<h2>Smart Cities en EspaÃ±a</h2>
<p>EspaÃ±a es un paÃ­s que ha invertido enormemente en el uso de energÃ­as renovables y en desarrollo sostenible. De hecho, actualmente, las energÃ­as renovables cubren en torno al 14% del consumo total del paÃ­s (3), y tiene un plan de crecimiento de su uso en el que se ha marcado como objetivo cubrir el 20% para el aÃ±o 2020.</p>
<p>Para el uso eficiente de esta energÃ­a generada en espacios urbanos, es esencial la transformaciÃ³n de ciudades en Smart Cities, y en EspaÃ±a tambiÃ©n hay una fuerte inversiÃ³n en el uso de las TIC (4). Existen mÃ¡s de 50 ciudades que conforman una red espaÃ±ola de ciudades inteligentes llamadas RECI, con el objetivo de, ademÃ¡s de aprovechar al mÃ¡ximo los recursos energÃ©ticos, mejorar los servicios de estas ciudades y reducir el gasto pÃºblico, generando asÃ­ progreso y atrayendo actividad econÃ³mica.</p>
<img src="images/ilu2.png" alt="Mapa de ciudades que conforman la RECI"></img>
<p>La Red EspaÃ±ola de Ciudades Inteligentes (5) divide sus actividades en cinco grupos de trabajo, segÃºn el objetivo de las TIC implantadas:</p>
<ul>
<li>InnovaciÃ³n Social: Trata mejoras en accesibilidad, cultura, participaciÃ³n ciudadana, salud, seguridad y emergencias, turismo y ocio, educaciÃ³n y gobierno abierto y open data.</li>
<li>EnergÃ­a: Alberga problemas de informaciÃ³n ciudadana sobre eficiencia energÃ©tica y de instalaciones de energÃ­as renovables, alumbrado pÃºblico y edificios â€œsmart spaceâ€�.</li>
<li>Medio Ambiente, Infraestructuras y Habitabilidad Urbana: Para temas de calidad ambiental, sostenibilidad de edificios e infraestructuras pÃºblicas, gestiÃ³n de parques y jardines pÃºblicos, recogida de residuos, mediciÃ³n de parÃ¡metros ambientales y urbanismo.</li>
<li>Movilidad urbana: Con sistemas inteligentes de transportes y movilidad elÃ©ctrica.</li>
<li>Gobierno, EconomÃ­a y Negocios: Que trata temas de administraciÃ³n electrÃ³nica, nuevos modelos de negocio, empleo, comercio electrÃ³nico, CPDs virtuales y entornos cloud.</li>
</ul>
<h2>El proyecto Smart Santander</h2>
<p>Smart Santander (6) es una iniciativa para crear un banco de experimentos o testbed en el que se puedan desarrollar y probar aplicaciones y servicios para smart cities. Ofrece una interfaz de acceso a los datos que generan unos 20.000 sensores colocados a lo largo de las ciudades de Belgrado (Serbia), Guildford (Inglaterra), LÃ¼beck (Alemania) y Santander (EspaÃ±a, con 12.000 sensores) que recogen medidas relacionadas con la movilidad urbana y el medio ambiente.</p> 
<img src="images/ilu3.png" alt="Esquema de arquitectura del proyecto SmartSantander"></img>
<p>La arquitectura del testbed comienza con la colocaciÃ³n de una red de sensores y repetidores a lo largo de la ciudad, llamados nodos IoT, los cuales leen o repiten los parÃ¡metros que generan los sensores utilizando el protocolo 802.15.4 de comunicaciÃ³n de dispositivos de bajo consumo. </p>
<p>La informaciÃ³n generada se envÃ­a a varios gateways que funcionan a modo de puerta de comunicaciÃ³n entre la infraestructura de sensores y los servidores centrales a los que se conectan los diferentes clientes a travÃ©s de varias capas de servicios que se ofrecen: AutenticaciÃ³n, soporte de experimentos, gestiÃ³n del testbed y soporte de aplicaciones.</p>
<p>Actualmente existen varios experimentos que utilizan el testbed de SmartSantander como fuente de datos para probar las aplicaciones y herramientas que desarrollan. Entre ellos destacan los siguientes:</p>
<ul>
    <li>Mitos: AplicaciÃ³n para generar mapas de rutas entre varios puntos. Utiliza los datos de SmartSantander para aÃ±adir tambiÃ©n informaciÃ³n en tiempo real de trÃ¡fico, aparcamientos y ruido. Ofrece tambiÃ©n un sistema de predicciÃ³n de la mejor zona para aparcar en el momento.</li>
    <li>Smart Travel: Utilizando los datos de trÃ¡fico de SmartSantander, realiza una estimaciÃ³n con un modelo de flujo de trÃ¡fico e informa de posibles puntos de congestiÃ³n, para que el usuario pueda elegir la ruta mÃ¡s eficiente hacia su destino.</li>
    <li>InterDataNet: Este experimento consiste en la elaboraciÃ³n de una herramienta web para la monitorizaciÃ³n de todos los sensores de la infraestructura IoT, mostrando las medidas de cada uno en un mapa de la ciudad.</li>
    <li>SEN2SOC: Pretende desarrollar una aplicaciÃ³n mÃ³vil en la que los usuarios puedan visualizar informaciÃ³n y alertas sobre los datos leÃ­dos por los sensores, asÃ­ como eventos sociales de la ciudad recogidos mediante un anÃ¡lisis de la informaciÃ³n de redes sociales.</li>
</ul>
<h1>Desarrollo</h1>
<p>A continuaciÃ³n se describe el proceso de desarrollo seguido para la elaboraciÃ³n de la arquitectura Big Data del proyecto. Se comienza con una visiÃ³n global del producto que se desea construir, para posteriormente ir desgranando en detalle cada uno de los elementos desarrollados y terminar finalmente con la visualizaciÃ³n final de datos diseÃ±ada.</p>
<h2>Objetivos del proyecto</h2>
<p>El proyecto consiste en realizar un nuevo experimento con el testbed del proyecto SmartSantander, que recoja los datos que genera la infraestructura de sensores que compone la Smart City.</p>
<p>Se desea utilizar tecnologÃ­a Big Data para tratar toda esa informaciÃ³n y generar varios anÃ¡lisis avanzados de los datos recolectados.
Punto por punto, cada uno de los objetivos del proyecto son los que se describen a continuaciÃ³n:</p>
<ul>
    <li>OBJ-01. En primer lugar, se realizarÃ¡ una visualizaciÃ³n de informaciÃ³n agregada de las diferentes medidas de los sensores en un mapa web. Este mapa debe ofrecer los distintos puntos donde se colocan los sensores, mostrando las medidas promedio en un intervalo de tiempo especÃ­fico seleccionado por el usuario para una magnitud tambiÃ©n elegida. En principio, se utilizarÃ¡ el cuarto de hora como intervalo de agregaciÃ³n de datos.</li>
    <li>OBJ-02. Esta informaciÃ³n se desea tener accesible lo mÃ¡s rÃ¡pido posible, por lo que tambiÃ©n se desea construir un proceso en tiempo real que vaya calculando los agregados de los intervalos temporales actuales, asÃ­ como que se ofrezcan lo mÃ¡s rÃ¡pidamente posible a travÃ©s de la interfaz web.</li>
    <li>OBJ-03. En segundo lugar, se desea realizar algÃºn tipo de anÃ¡lisis estadÃ­stico avanzado de la informaciÃ³n. Se va a diseÃ±ar un algoritmo de clustering que clasifique los dÃ­as segÃºn el comportamiento de una de sus medidas, concretamente la temperatura. Se debe construir ademÃ¡s una interfaz web intuitiva con la que se puedan explorar los resultados de cada uno de los grupos generados, asÃ­ como poder compararlos con las medidas de los dÃ­as que hayan entrado en el proceso de cÃ¡lculo.</li>
    <li>OBJ-04. Al ser un proyecto Big Data, se desea tambiÃ©n que los procesos de cÃ¡lculo, almacenamiento y anÃ¡lisis de la informaciÃ³n sean escalables, de manera que se elija la tecnologÃ­a que mejor se adapte a cada una de las partes de la arquitectura que se diseÃ±e y se construya.</li>
    <li>OBJ-05. Finalmente, se prefiere utilizar herramientas de Big Data de uso en la actualidad y que no se hayan impartido en clase, con el fin de completar los conocimientos adquiridos con experiencia en otras tecnologÃ­as emergentes; como por ejemplo utilizar Apache Spark para procesamiento offline de la informaciÃ³n.</li>
</ul>
<h2>Arquitectura de la soluciÃ³n</h2>
<p>Para diseÃ±ar la arquitectura Big Data de la soluciÃ³n, es necesario primero ir punto por punto de los objetivos y definir para cada uno de ellos las herramientas tecnolÃ³gicas ideales para desarrollar dichas tareas.</p>
<p>Todos los objetivos anteriores requieren obtener previamente los datos emitidos por la arquitectura IoT del testbed de Santander, por lo que habrÃ¡ que aÃ±adir un objetivo secundario que comprende la adquisiciÃ³n y almacenamiento de datos emitidos por los sensores.
Para esta primera tarea de adquisiciÃ³n, es conveniente elaborar un estudio inicial de la informaciÃ³n a recopilar. Se partirÃ¡ de una interfaz web que ya ofrece el equipo de SmartSantander en su pÃ¡gina web con un mapa con los datos actuales de cada uno de los sensores, en cada una de las magnitudes que miden.</p>
<img src="images/ilu4.png" alt="Interfaz web con acceso a los datos de sensores de SmartSantander"></img>
<p>Para ayudar en la inserciÃ³n, se desarrollarÃ¡ un proceso que leerÃ¡ cada cierto tiempo los datos de la web y los almacenarÃ¡.</p>
<p>Este almacÃ©n de datos debe ser leÃ­do posteriormente por un proceso que distribuya la informaciÃ³n en un sistema de ficheros HDFS. Para llevar esa tarea, se almacenarÃ¡n las lecturas en una cola Apache Kafka, ya que es una herramienta escalable que permite llevar un offset del mensaje que cada uno de los consumidores va leyendo, permitiendo interrumpir y continuar la carga donde se dejÃ³ la Ãºltima vez. Dicho consumidor serÃ¡ un agente Flume, que lea los mensajes, les pueda aplicar un tratamiento de limpieza y almacene finalmente las lecturas de manera distribuida y preparada para su acceso posterior por parte de cada una de las herramientas que se tengan que construir en cada uno de los objetivos indicados.</p>
<p>Para el objetivo OBJ-01 referente a la visualizaciÃ³n de las medidas agregadas de cada uno de los sensores por cada cuarto de hora, se necesitarÃ¡ realizar un proceso offline de tratamiento de datos que agregue y almacene de manera accesible por la web la informaciÃ³n de las lecturas de datos. Para ello se construirÃ¡ un job utilizando Apache Spark que lea los ficheros del HDFS y agregue la informaciÃ³n para posteriormente almacenarla en una base de datos columnar que agilice el acceso a los datos desde la interfaz web. La base de datos elegida es Cassandra, que aporta unos tiempos de escritura bastante rÃ¡pidos y permite la escalabilidad sin tener un punto Ãºnico de fallo. Para acceder a esta base de datos por parte de la interfaz web, se construirÃ¡ una API REST utilizando Spring que reciba las peticiones de los usuarios y acceda a la base de datos de Cassandra, que tendrÃ¡ una tabla optimizada para cada una de las querys que la web necesite. La interfaz web se implementarÃ¡ utilizando ExtJS, junto con componentes HTML5 y JQuery que mostrarÃ¡n los datos.</p>
<p>En cuanto al objetivo OBJ-02, en el que se pretende acceder en tiempo real al valor agregado actual de los datos de los sensores, se construirÃ¡ una topologÃ­a con Apache Storm que acceda directamente a la cola Kafka de recepciÃ³n de los mensajes, limpie la informaciÃ³n, la agregue en el cuarto de hora actual y la almacene en la misma tabla de la base de datos Cassandra donde la almacena el proceso batch descrito anteriormente. Ambos procesos convivirÃ­an siguiendo el patrÃ³n de arquitecturas lambda para el procesamiento offline y online de la informaciÃ³n de un sistema Big Data.</p>
<p>Para realizar el objetivo OBJ-03, el desarrollo de un algoritmo de clustering que clasifique dÃ­as en base a alguna de las magnitudes, se crearÃ¡ un nuevo job con Spark que recoja y agregue la informaciÃ³n para despuÃ©s pasarla a un clÃºster K-Means utilizando la librerÃ­a MLLib que implementa este mismo algoritmo de manera distribuida y escalable. El resultado de la ejecuciÃ³n se almacenarÃ¡ tambiÃ©n en la misma base de datos Cassandra para que sea accesible a travÃ©s de la API REST. Para determinar el nÃºmero de grupos Ã³ptimo, se realizarÃ¡ previamente un estudio, observando la variaciÃ³n de la suma de errores cuadrÃ¡ticos en cada uno de los k valores posibles. La visualizaciÃ³n de la informaciÃ³n se realizarÃ¡ con una nueva webapp utilizando ExtJS que ataque a la API REST, al igual que en el OBJ-01.</p>
<p>Todos los componentes descritos anteriormente conforman la arquitectura de la soluciÃ³n. En resumen, estos componentes son:</p>
<ul>
<li>Una aplicaciÃ³n de web scrapping que recoja las fuentes</li>
<li>Una cola Kafka que reciba y almacene temporalmente las fuentes recibidas desde el web scrapper.</li>
<li>Un agente Flume que lea de la cola Kafka, realice un proceso de limpieza de la informaciÃ³n y almacene los datos de manera distribuida.</li>
<li>Un sistema de ficheros HDFS que recibe los datos del agente Flume.</li>
<li><p>Un servidor Spark que se encargue del procesamiento batch, a priori de dos jobs:</p>
    <ul>
       <li>Un job encargado de la agregaciÃ³n de la informaciÃ³n.</li>
       <li>Un job que con MLLib calcule un algoritmo de clustering con los datos de una de las medidas.</li>
    </ul>
</li>
<li>Un servicio Storm que lea de la cola Kafka utilizando otro consumidor que no sea el del proceso Flume y que agregue la informaciÃ³n de las mediciones actuales de los sensores.</li>
<li>Una base de datos Cassandra que almacene los resultados tanto de los jobs del servidor Spark como de la topologÃ­a del servicio Storm.</li>
<li>Una API REST hecha con Spring que sirva de interfaz entre peticiones de datos de usuarios externos y la base de datos Cassandra con los resultados de los procesos online y offline.</li>
<li><p>Un servidor Apache Tomcat de aplicaciones web en el que se publicarÃ¡n dos pÃ¡ginas de visualizaciÃ³n de datos:</p>
    <ul>
        <li>Una pÃ¡gina que dibuje en un mapa los datos de los sensores por cada medida y agregaciÃ³n temporal calculada.</li>
        <li>Una pÃ¡gina que muestre y permita interactuar con los resultados de la ejecuciÃ³n del algoritmo de clustering.</li>
    </ul>
</li>
</ul>
<p>En resumen, la arquitectura software que se pretende construir presenta el siguiente esquema:</p>
<img src="images/ilu5.png" alt="Arquitectura Software de la soluciÃ³n"></img>
<h2>DiseÃ±o de los elementos de la arquitectura</h2>
<p>Una vez construido el diseÃ±o general de la soluciÃ³n Big Data, se ha procedido a diseÃ±ar y construir cada uno de los componentes que la forman. En este apartado se explican con detalle todos estos componentes, asÃ­ como los problemas encontrados durante su implementaciÃ³n.</p>
<h3>Proceso de web scrapping</h3>
<p>El proceso de web scrapping tiene bÃ¡sicamente el objetivo de leer cada cierto intervalo de tiempo los datos de sensores de la web fuente y almacenarlos en una cola Kafka.</p>
<p>Para ello, se ha creado una aplicaciÃ³n Java que recibe tres parÃ¡metros:</p>
<ul>
<li>u: conjunto de urls, separadas por coma, de las que el proceso harÃ¡ scrapping.</li>
<li>i: intervalos de tiempo en segundos entre peticiÃ³n y peticiÃ³n.</li>
<li>k: direcciÃ³n y puerto donde se localiza la cola Kafka en la cual se almacenarÃ¡n las pÃ¡ginas leÃ­das.</li>
</ul>
<p>La aplicaciÃ³n abrirÃ¡ un hilo de ejecuciÃ³n por cada url que se pase por parÃ¡metro. Cada hilo harÃ¡ una peticiÃ³n de descarga de contenido a su url especÃ­fica cada cierto tiempo, determinado por el parÃ¡metro de intervalo, almacenÃ¡ndolo posteriormente en la cola Kafka.</p>
<p>Para marcar el tiempo en el que un contenido fue descargado, se incluye al inicio de cada mensaje que irÃ¡ a la cola Kafka la fecha y hora en la que fue descargado, separado posteriormente con el carÃ¡cter â€˜~â€™, de manera que en procesos posteriores de limpieza de los mensajes se pueda extraer y utilizar.</p>
<p>Esta aplicaciÃ³n se ha hecho genÃ©rica, para que pueda ser utilizada no solo con el proyecto SmartSantander, sino en otros en los que se requiera realizar un web scrapping que almacene el contenido leÃ­do en una cola Kafka.</p>
<p>El cÃ³digo de la aplicaciÃ³n se encuentra bajo la carpeta ssscrapper y se ha hecho utilizando Eclipse y Maven para gestionar las dependencias de librerÃ­as Java.</p>
<p>Contiene principalmente dos clases localizadas en el mismo paquete (com.utad.pebd.marcosgarciacasado.ssscrapper):</p>
<ul>
<li>SSScrapper: Clase principal a la que se debe de llamar. Se encarga de parsear los argumentos y lanzar los hilos de ejecuciÃ³n para cada url de descarga.</li>
<li>URLPeriodicDownload: Clase runnable que descarga cada cierto periodo de tiempo el contenido de la url asociada a una cola Kafka.</li>
</ul>
<p>Para interrumpir la descarga es necesario matar el proceso, puesto que cada uno de los hilos ejecuta un bucle infinito de peticiones en cada intervalo temporal.</p>
<p>En este proyecto en especÃ­fico, se debe leer de un mapa web localizado en la url maps.smartsantander.eu. Se deben descargar los datos de dos mapas diferentes: el del apartado IoT Infraestructure, en el que se encuentran los sensores fijos de la red de Santander, y el mapa del apartado Mobile Sensing, que contiene las mediciones de los sensores wireless instalados en unidades mÃ³viles como taxis o autobuses.</p>
<p>Analizando el cÃ³digo de esta pÃ¡gina web, se puede apreciar que estos mapas cargan sus datos desde dos scripts php que devuelven un objeto JSON con una cierta estructura. Dichos scripts se llaman getdata.php (para el mapa IoT Infraestructure) y getdatatus.php (para el mapa Mobile Sensing).</p>
<p>Cada elemento del objeto JSON corresponde con los datos de un sensor, que puede tener varias mediciones de distintas magnitudes, dependiendo de su tipo. Estas mediciones vienen encapsuladas en cÃ³digo HTML correspondiente con el popup que se muestra cuando se hace click en un marcador de sensor del mapa. En posteriores pasos se procede a analizar dicho HTML y extraer la mediciÃ³n de cada magnitud.</p>
<p>Para la parte de almacenamiento, se ha instalado una cola Kafka y se ha creado un nuevo tÃ³pico llamado â€œssdaâ€� donde se almacenarÃ¡n todos estos mensajes producidos por el web scrapper.</p>
<p>En cuanto al nÃºmero de segundos de intervalo, se ha decidido utilizar 15 segundos, ya que se prevÃ© de esta manera obtener casi todas las actualizaciones de mediciones de datos. Cada descarga de los objetos JSON ocupa 1MB aproximadamente, por lo que se puede estimar la cantidad de informaciÃ³n que se almacenarÃ¡ diariamente en la cola Kafka:</p>
<p>(1MB/intervalo * 60 segundos/minuto * 60 minutos/hora * 24 horas/dÃ­a) / 15 segundos/intervalo = 5.62 GB/dÃ­a</p>
<p>La cola Kafka se ha configurado para que almacene los Ãºltimos 5 dÃ­as con un factor de replicaciÃ³n de 1, por lo que el  tamaÃ±o necesario para almacenarla es aproximadamente de 28.1 GB.</p>
<p>La llamada al proceso por lo tanto tendrÃ¡ que hacerse una vez arrancada la cola Kafka y con los siguientes parÃ¡metros:</p>
<ul>
<li>u: maps.smartsantander.eu/getdata.php, maps.smartsantander.eu/getdata.php</li>
<li>i: 15</li>
<li>k: localhost:2181</li>
</ul>
<h3>Proceso de ingestiÃ³n de datos y almacenamiento</h3>
<p>Una vez se tenga la informaciÃ³n almacenada en la cola Kafka, el siguiente paso es el de leer dicha cola y almacenarla en un sistema de ficheros distribuido como HDFS. Para ello se ha utilizado Apache Flume, en el que un agente leerÃ¡ como consumidor de mensajes la cola â€œssdaâ€� de Kafka, realizarÃ¡ un tratamiento de limpieza de los objetos JSON para extraer los valores de las magnitudes leÃ­das por sensor. Finalmente, se ha configurado un sink HDFS para almacenar los datos en varios ficheros cuyo formato se describe posteriormente en este apartado.</p>
<h4>Source</h4>
<p>El Source que se ha de configurar en el agente Flume debe ser capaz de leer los mensajes de una cola Kafka. En la instalaciÃ³n inicial de Flumen no se encuentra ese elemento, por lo que se ha descargado y aÃ±adido uno diferente, localizado en github.com/baniuyao/flume-ng-kafka-source. Este artefacto es compatible con la versiÃ³n 0.7.2 de Kafka y no con las versiones actuales 0.8.1, por lo que se ha tenido que estudiar el cÃ³digo y refactorizar las peticiones del consumidor Kafka para que se pueda utilizar con nuevas versiones.</p>
<p>Por otro lado, no se pretende almacenar los mensajes fuente tal y como se descargan, sino reestructurar los objetos JSON leÃ­dos de manera que se pueda extraer del contenido HTML que cada uno de ellos tiene los valores de cada una de las magnitudes de los sensores. Para ello, se ha construido un interceptor personalizado que se encarga de reformatear los objetos JSON antes de almacenarlos en HDFS. El cÃ³digo del proyecto Eclipse de este interceptor se encuentra en la carpeta ssjsonformatterinteceptor.</p>
<p>Por cada mensaje, se tiene por un lado la fecha en la que fue descargado de la web, aÃ±adida directamente en el web scrapper, seguido de un array JSON en el que cada elemento es una lectura de un sensor completo. Este objeto JSON tiene la siguiente estructura:</p>
<ul>
<li>id: cÃ³digo de identificaciÃ³n del sensor dentro de la red IoT</li>
<li>latitude: latitud de la posiciÃ³n del sensor</li>
<li>longitude: longitud de la posiciÃ³n del sensor</li>
<li>title: nombre del sensor</li>
<li>image: url al icono del marcador del sensor en el mapa web</li>
<li>content: contenido HTML del popup del marcador, en el que se encuentran los valores de todas las magnitudes que el sensor mide en el momento de la extracciÃ³n</li>
<li>tags: tipo de sensor</li>
</ul>
<p>Por cada tag o tipo de sensor, se tienen diferentes magnitudes de las que se puede extraer su valor. El interceptor lo que hace por lo tanto es leer el tag y extraer unas medidas u otras dependiendo de su valor. Una vez se pasa un objeto JSON por el interceptor, queda de la siguiente manera:</p>
<ul>
<li>tags: tipo de sensor
<li>latitude: latitud de la posiciÃ³n del sensor
<li>longitude: longitud de la posiciÃ³n del sensor
<li>title: nombre del sensor
<li>id: cÃ³digo de identificaciÃ³n del sensor dentro de la red IoT
<li>last-update ultima fecha de actualizaciÃ³n de la informaciÃ³n del sensor. Esta fecha puede aparecer o no, dependiendo del tipo de sensor.
<li>battery: nivel de energÃ­a del sensor
<li>requesttime: fecha y hora de la descarga de la mediciÃ³n
<li><p>medidas: al mismo nivel que el resto, aparecen diferentes magnitudes que los sensores ofrecen. Estas magnitudes pueden ser de los siguientes tipos:</p>
<ul>
    <li>humidity: porcentaje de humedad del aire.</li>
    <li>altitude: altitud sobre el nivel del mar en metros.</li>
    <li>wind-speed: velocidad del viento en km/h.</li>
    <li>soil-moisture: cantidad de agua en tierra.</li>
    <li>noise: nivel de ruido en decibelios.</li>
    <li>co-index: nivel de CO2 en el aire.</li>
    <li>parking: porcentaje de espacio de aparcamiento libre.</li>
    <li>odometer: kilÃ³metros recorridos por el medio de transporte del sensor.</li>
    <li>speed: velocidad en km/h.</li>
    <li>temperatura: temperatura en grados Celsius.</li>
    <li>atmospheric-pressure: presiÃ³n atomosfÃ©rica.</li>
    <li>soil-temperature: temperatura del suelo.</li>
    <li>count: conteo de vehÃ­culos en trÃ¡nsito.</li>
    <li>occupancy: cantidad de plazas ocupadas en el medio de transporte</li>
    <li>rainfall: nivel de precipitaciones.</li>
    <li>solar-radiation: radiaciÃ³n solar.</li>
    <li>luminosity: porcentaje de luminosidad</li>
    <li>relative-humidity: porcentaje de humedad relativa del aire</li>
</ul>
</li>
</ul>
<p>AdemÃ¡s de formatear los mensajes JSON, el interceptor se encarga tambiÃ©n de reducir el espacio utilizado, almacenando Ãºnicamente aquellas mediciones que han variado; evitando insertar informaciÃ³n duplicada. Para ello mantiene una tabla hash en la que la clave es el campo title de cada sensor y el valor es el cÃ³digo hash de la concatenaciÃ³n del campo content con el campo image. Cuando viene un nuevo mensaje, se comprueba si el sensor se encuentra en la tabla hash y si el hashcode del contenido coincide con el almacenado. En caso de ser verdad, se descarta el mensaje; y si en cambio es falso, se aÃ±ade el nuevo cÃ³digo hash a la tabla y se procesa y almacena el mensaje entrante.</p>
<p>Gracias a esta modificaciÃ³n que controla si el dato ha variado o no, se ha reducido considerablemente la cantidad de informaciÃ³n que se almacena. Tras ejecutar las pruebas necesarias para medir el almacenamiento que genera el proceso de ingestiÃ³n, se pasa de necesitar una cantidad de almacenamiento similar a la de los mensajes originales, unos 5.6 GB al dÃ­a, a necesitar simplemente 50 MB por dÃ­a (un 99% menos).</p>
<h4>Channel</h4>
<p>El proceso no recibe datos a una velocidad problemÃ¡tica como para quedarse sin memoria en algÃºn momento, por lo que el canal configurado es de tipo in-memory, permitiendo una velocidad mayor que si se configura para que los mensajes se guarden en disco persistente.</p>
<h4>Sink</h4>
<p>El sink del agente envÃ­a los mensajes al sistema de almacenamiento HDFS. Para cerrar ficheros frecuentemente y no tener la posibilidad de perder mucha informaciÃ³n en el caso de que el proceso de ingestiÃ³n falle, el sink estÃ¡ configurado para escribir en ficheros nuevos cada 15 minutos. Estos ficheros se clasifican tambiÃ©n en carpetas, teniendo una por aÃ±o y dentro de ellas, una por cada mes.</p>
<p>El formato de almacenamiento permite que en algÃºn momento se pueda crear una tabla externa con Hive con la que hacer querys rÃ¡pidamente a todos los ficheros, utilizando el JSON SerDe como parser.</p>
<p>Como ya se indicÃ³ anteriormente, cada dÃ­a se almacenan alrededor de 50MB de informaciÃ³n de sensores. Con un factor de replicaciÃ³n 3, esto aumenta a 150MB, con lo que el crecimiento de los datos mensual serÃ­a de aproximadamente 4.4GB. </p>
<p>Inicialmente no es un problema Big Data en cuanto a la volumetrÃ­a de la informaciÃ³n a tratar, pero el proceso estÃ¡ preparado para aÃ±adir mÃ¡s informaciÃ³n, ya sea por el crecimiento temporal indicado o por la inclusiÃ³n de nuevos sensores o de nuevas ciudades en el almacÃ©n.</p>
<h3>Procesamiento batch de tratamiento de la informaciÃ³n</h3>
<p>El proceso batch que se ha desarrollado trata de agregar la informaciÃ³n almacenada en HDFS y guardarla en una base de datos Cassandra. El cÃ³digo de este paso se encuentra en la carpeta ssbatch. Es un proyecto Eclipse que utiliza Maven y estÃ¡ codificado en Scala.</p>
<h4>ElecciÃ³n de herramientas de procesamiento</h4>
<p>Para los procesos offline que se han construido, se ha decidido utilizar Spark, ya que es una herramienta emergente que aspira a sustituir a MapReduce, al poder controlar el almacenamiento en memoria o en disco de las estructuras de datos distribuidos, llamados RDDs, ofreciendo una velocidad mayor puesto que ahorra accesos a memoria persistente.</p>
<p>En cuanto a la codificaciÃ³n de los jobs, se ha elegido utilizar Scala, un lenguaje sencillo que puede importar librerÃ­as Java y que tiene su propia API Spark.</p>
<p>Para conectar la base de datos Cassandra con Spark se ha utilizado el plugin cassandra-spark de la empresa Datastax con el que se puede almacenar directamente un RDD a una tabla de forma distribuida.</p>
<h4>Filtro de datos espurios</h4>
<p>El primer job que se ha desarrollado se llama SSEstimateCI. Se encarga de realizar un filtro de los datos, con el fin de descartar para el cÃ¡lculo de los agregados aquellas mediciones que puedan ser errÃ³neas. Para ello, se ha hecho un job auxiliar que calcule la media y la desviaciÃ³n tÃ­pica de cada una de las magnitudes. Estas medias y desviaciones se almacenan en una tabla de la base de datos Cassandra (la tabla ssda.ss_measures_stats).</p>
<p>Para calcular la media, se recoge en una fase map los pares medida y valor. En la fase combine/reduce se suman los valores por un lado y se cuenta la cantidad de estos por otro. Para extraer la media, se divide la suma por el conteo final.</p>
<p>Para la desviaciÃ³n tÃ­pica, se utilizan las medias calculadas previamente para medir en una fase map la distancia de cada valor a esta. Se suman estas potencias al cuadrado en una fase reduce, junto con el conteo de los valores que hay y para extraer el resultado se divide la suma de potencias por la cantidad de valores menos 1 y despuÃ©s se extrae su raÃ­z cuadrada.</p>
<h4>Agregado de valores filtrados</h4>
<p>Este job es el proceso de agregado inicial. Se llama SSBatchProcess. Utiliza el resultado del job previo SSEstimateCI, por lo que es necesario que este se ejecute antes.</p>
<p>Cada elemento que lee el job es un conjunto de mediciones de un sensor. Queremos guardar un dato por cada medida, por lo que lo primero que se hace es ejecutar un flatMap en el que se emitan tantas filas por sensor como valores muestre. Para las medidas que salgan de cada sensor, se mapean para obtener pares clave valor (k, v), en los que k serÃ¡ la combinaciÃ³n de la latitud, la longitud  y el cuarto de hora en el que entre la fecha de recogida del dato; y como valor la magnitud y su valor medido.</p>
<p>A continuaciÃ³n, se leen de Cassandra la media y la desviaciÃ³n tÃ­pica de cada medida, almacenÃ¡ndolos en un HashMap para poder aplicar a continuaciÃ³n un filtro de datos espurios. En un map que recorra los datos, los valores que sumen al agregado son aquellos que se encuentren en el intervalo ð�œ‡âˆ’2ð�œŽ, ð�œ‡+2ð�œŽ, siendo Âµ la media y Ïƒ la desviaciÃ³n tÃ­pica.</p>
<p>Con los datos filtrados se procede a agrupar los pares clave valor para calcular el agregado. Se calcula la media, por lo que en la agregaciÃ³n se recoge por un lado la suma de los valores y por otro el conteo. Finalmente, para obtener la media se realizarÃ­a una divisiÃ³n entre ellos.</p>
<p>Una vez se tiene el agregado calculado, se almacena en la base de datos de Cassandra. La tabla destino se llama ss_measures_agr y tiene los campos measure, time, latitude, longitude y value. La Row Key es (measure, time) para optimizar la consulta de las mediciones de una magnitud en un cuarto de hora concreto.</p>
<p>TambiÃ©n se guarda posteriormente en otra tabla llamada ss_measures_ts_agr con los mismos campos, pero esta vez la rowkey es measure, latitude y longitude; de manera que se puedan sacar de forma Ã³ptima series temporales con el histÃ³rico de mediciÃ³n de la medida elegida en las coordenadas seleccionadas.</p>
<h3>Procesamiento real-time de tratamiento de la informaciÃ³n</h3>
<p>El proceso real-time realiza el mismo cÃ¡lculo que el proceso batch de cÃ¡lculos de agregado, con la diferencia de que lee de la cola Kafka de mensajes directamente y escribe en Cassandra el agregado del cuarto de hora actual, actualizÃ¡ndolo cada vez que cambia la informaciÃ³n. El decalaje de tiempo entre que cambia el dato y se muestra en la visualizaciÃ³n es simplemente el tiempo que tarda en ser recogido por el web-scrapper, el tiempo que tarde la cola Kafka en leer el mensaje del productor y enviÃ¡rselo al consumidor, y el tiempo que tarde el proceso real-time en agregar la informaciÃ³n y almacenarla en las tablas de Cassandra de las que se alimenta el visor web.</p>
<h4>ElecciÃ³n de herramientas de procesamiento</h4>
<p>La herramienta elegida para implementar este servicio ha sido Storm, ya que permite aumentar fÃ¡cilmente el nÃºmero de nodos de cÃ³mputo y por otro lado asegura que todos los mensajes lleguen a ser procesados.</p>
<p>Se ha diseÃ±ado e implementado una topologÃ­a en la que cada uno de los pasos tiene una tarea sencilla y que en conjunto realizan todo el trabajo que se desea.</p>
<h4>TopologÃ­a</h4>
<p>La topologÃ­a que se ha diseÃ±ado consta de 5 capas: 1 capa de spouts y 4 de bolts. Todas se comunican secuencialmente, habiendo un Ãºnico camino en el trÃ¡nsito de los datos:</p>
<img src="images/ilu6.png" alt="Esquema de topologÃ­a del proceso Storm"></img>
<p>Las cinco capas de la topologÃ­a son las siguientes:</p>
<ul>
<li>KafkaSpout: Conector de Kafka que introduce los mensajes de la cola con el tÃ³pico â€œssdaâ€� a la red de procesos de la topologÃ­a Storm. Este spout lo ofrece Apache Storm, su dependencia Maven se llama storm-kafka.</li>
<li>JsonFormatterBolt: El JsonFormatterBolt recibe como librerÃ­a el interceptor que se hizo para el proceso Flume de ingestiÃ³n de datos y utiliza la funciÃ³n para formatear el mensaje con las medidas de los sensores a un objeto JSON, con el fin de que en el resto de pasos se puedan leer sus valores.</li>
<li>MeasureFlattenerBolt: Este bolt se encarga de recoger cada uno de los JSON formateados previamente y emitir varios mensajes, uno por cada medida. De esta manera, cada mensaje emitido por esta capa tiene un valor de una medida correspondiente.</li>
<li>ContinuousAggregatorBolt: Recibe los mensajes de cada medida obtenida y realiza el agregado. Para ello, gestiona en una tabla hash la suma parcial que va obteniendo, reseteando los valores a cero cada vez que pasa un cuarto de hora. Como cada nodo tiene un agregado, no puede haber dos en los que vaya calculando las mismas medidas, por lo que hay que dirigir el trÃ¡fico de cada magnitud a un nodo en concreto de esta capa (sharding). Como resultado, envÃ­a la media actual del valor que el mensaje haya actualizado.</li>
<li>CassandraSaveBolt: Este Ãºltimo paso se encarga simplemente de preparar una query de inserciÃ³n en la base de datos Cassandra, concretamente en la tabla ss_measures_agr, e insertar el valor recibido del actual cuarto de hora.</li>
</ul>
<p>Al guardar los datos agregados en la misma tabla que lo guardaba el proceso batch, se integran automÃ¡ticamente ambos resultados y es transparente para el usuario el funcionamiento interno del proceso de actualizaciÃ³n de la informaciÃ³n que ve. Este patrÃ³n de integraciÃ³n de la parte de tiempo real con la parte offline es lo que se conoce como arquitectura lambda.</p>
<h3>Proceso de cÃ¡lculo de clÃºster</h3>
<p>El objetivo del proceso de clÃºster es el de lanzar un algoritmo de clustering para clasificar los dÃ­as en los que se tenga datos en varios grupos, de manera que los dÃ­as de un grupo tengan una distribuciÃ³n parecida de valores de la magnitud estudiada por cada cuarto de hora. Se ha escogido la temperatura como magnitud para realizar el estudio.</p>
<h4>ElecciÃ³n de la herramienta de cÃ¡lculo analÃ­tico a utilizar</h4>
<p>Se ha optado por utilizar la librerÃ­a MLLib de Spark, ya que tiene un algoritmo para calcular de manera distribuida el clÃºster, pudiendo tener los datos de entrada en un RDD distribuido a lo largo del clÃºster. La ventaja de esto es que el cÃ¡lculo tambiÃ©n serÃ­a escalable, reduciÃ©ndose proporcionalmente el tiempo de ejecuciÃ³n a medida que se aÃ±aden nodos al clÃºster de Spark.</p>
<h4>DefiniciÃ³n de variables</h4>
<p>El primer paso para desarrollar el algoritmo consiste en definir las variables del modelo, las cuales serÃ¡n la media de las temperaturas de los sensores por cada cuarto de hora. En total se tienen 96 variables diferentes, una por cada cuarto de hora que tiene un dÃ­a completo. Cada elemento a clasificar se definirÃ¡ por la fecha en la que se extrajeron esas magnitudes, sin hora.</p>
<p>Finalmente hay que escoger el nÃºmero de clusters o agrupaciones en las que se van a clasificar los dÃ­as. Para ello, se hace un primer lanzamiento de varios cÃ¡lculos en los que cada uno tendrÃ¡ como parÃ¡metro un nÃºmero de clusters diferentes. Se ha ejecutado de 2 a 7 grupos. Lo que se extrae es el error cuadrÃ¡tico del modelo para cada lanzamiento, con el fin de mostrar cada uno de los valores en un grÃ¡fico. Se espera que el grÃ¡fico tenga una pendiente descendente y que en un momento se observe un cambio de tendencia en el que el error comience a converger a un valor. En ese punto es en el que habrÃ¡ que escoger el nÃºmero de agrupaciones para el lanzamiento del clÃºster final.</p>
<img src="images/ilu7.png" alt="GrÃ¡fico de valores de errores cuadrÃ¡ticos"></img>
<p>En el momento que se realizÃ³ el estudio para el cÃ¡lculo del nÃºmero Ã³ptimo de clusters, solo se tenÃ­an siete dÃ­as completamente rellenos con datos, por lo que el grÃ¡fico desciende hasta error 0 cuando se llega a 7 grupos. Se ha decidido coger 6 como nÃºmero de grupos de momento, pero es conveniente volver a buscar el nÃºmero Ã³ptimo de grupos cuando se tenga mÃ¡s dÃ­as almacenados en el HDFS. No obstante, ya se va observando un cambio de tendencia al ser la pendiente menos decreciente con mÃ¡s grupos.</p>
<h4>ConstrucciÃ³n del job para el lanzamiento del clÃºster</h4>
<p>El cÃ³digo fuente del proceso Spark de clustering estÃ¡ en el fichero SSClusterCalc.scala en el proyecto ssbatch.</p>
<p>Para preparar los datos antes del lanzamiento de la funciÃ³n de cÃ¡lculo, se recogen del HDFS, al igual que en el proceso de agregaciÃ³n de datos, se filtran para recoger Ãºnicamente los datos de temperatura y se agrupa una primera vez de la misma manera. El valor del agregado se encapsula posteriormente en un objeto de tipo ClusterValue (un par cuarto de hora - valor) y se pasa de nuevo por un paso de agregaciÃ³n, esta vez agrupando los valores por dÃ­as y utilizando la funciÃ³n groupByKey de Spark. De esta manera, se tiene para cada clave (dÃ­a)  se tiene un array de objetos de tipo ClusterValue, en el que dentro se encuentra el cuarto de hora y el valor de la media de temperatura. Ese array se ordena por el valor del cuarto de hora y se convierte en un Vector de nÃºmeros reales, que sirve de formato de entrada para el clÃºster.</p>
<p>Una vez que se han preparado los datos para la entrada del clÃºster, un RDD de vectores de reales, se ejecuta. Para ello se llama a la librerÃ­a MLLib, concretamente a la creaciÃ³n de un clÃºster KMeans con 6 grupos, 20 iteraciones de entrenamiento y el RDD formateado con los valores como entrada.</p>
<p>Una vez entrenado el modelo, se inserta en la base de datos Cassandra tanto la asociaciÃ³n de cada dÃ­a en su clÃºster, en la tabla ss_cluster_res, como los centroides de cada grupo, en la tabla ss_cluster_centers.</p>
<p>Estas dos tablas son las que leerÃ¡ la aplicaciÃ³n web posteriormente y con la que rellenarÃ¡ la visualizaciÃ³n.</p>
<h3>Sistema de acceso REST a la informaciÃ³n</h3>
<p>Para acceder a los datos desde puntos externos, se ha desarrollado una API REST para que sea utilizada posteriormente por las aplicaciones web u otras futuras que se desarrollen y que requieran consultar datos resultantes del tratamiento de datos realizado.</p>
<p>La herramienta que se ha decidido utilizar ha sido el framework Spring para hacer servicios REST. Este servicio recibe peticiones GET desde interfaces externas que normalmente corresponden con una query a la base de datos Cassandra y devuelve objetos JSON con los datos resultantes.</p>
<p>El cÃ³digo de esta secciÃ³n del proyecto se encuentra en la carpeta ssdataaccess y es un proyecto Gradle desarrollado con Eclipse. Los servicios implementados hasta ahora son los siguientes:</p>
<ul>
<li>measuremap: dado un cuarto de hora de un dÃ­a en concreto y una magnitud, devuelve los valores calculados para cada coordenada.</li>
<li>measurestats: devuelve la media y la desviaciÃ³n tÃ­pica calculada de cada una de las magnitudes.</li>
<li>clusterresults: devuelve el conjunto de dÃ­as que se han calculado en el proceso de clustering, junto con el identificador del grupo en el que se han clasificado.</li>
<li>clustercenter: devuelve los valores de los centroides de un clÃºster, cuyo identificador se pasa por parÃ¡metro. Los devuelve en forma de array de nÃºmeros reales.</li>
<li>dayresults: dado un dÃ­a y la magnitud, devuelve el conjunto de valores de cada cuarto de hora, como un array de nÃºmeros reales.</li>
</ul>
<h2>VisualizaciÃ³n de resultados</h2>
<p>En este apartado se describen las interfaces de visualizaciÃ³n de datos generadas, tanto las medidas agregadas que se han calculado como la visualizaciÃ³n de los resultados del clÃºster.</p>
<p>Para construir ambas visualizaciones se ha utilizado el framework ExtJs de creaciÃ³n de aplicaciones web en Javascript, y se han colocado en el mismo servidor Tomcat que el servidor de la API REST de acceso a datos. Esto es esencial, ya que las peticiones se hacen a travÃ©s de Ajax y no funciona dicho acceso a datos si no se encuentra bajo el mismo dominio y puerto.</p>
<h3>VisualizaciÃ³n de medidas agregadas</h3>
<p>Para visualizar las medidas agregadas se ha pensado construir un mapa donde se pinten con marcadores los sensores con informaciÃ³n de una magnitud elegida a travÃ©s de un combobox, en un cuarto de hora dado escogido en un selector de fecha y hora.</p>
<p>Estos marcadores se posicionan en el mapa dadas las coordenadas del sensor y al hacer click muestra el valor de la medida seleccionada. AdemÃ¡s, los marcadores varÃ­an de color, de colores mÃ¡s frÃ­os a mÃ¡s cÃ¡lidos, segÃºn su valor dentro del rango marcado por la media y la desviaciÃ³n tÃ­pica que se usÃ³ para calcular los filtros de datos espurios ð�œ‡âˆ’2ð�œŽ, ð�œ‡+2ð�œŽ.</p>
<img src="images/ilu8.png" alt="VisualizaciÃ³n de datos agregados en el mapa de Santander"></img>
<p>Para hacer el mapa se ha utilizado el servicio gratuito Mapbox, en el que se pueden guardar mapas personalizados. Utilizando su API para Javascript se han aÃ±adido los marcadores, que forman parte de la librerÃ­a Leaflet.js de elementos de visualizaciÃ³n de datos en mapas para JS.</p>
<h3>VisualizaciÃ³n de resultados del clÃºster</h3>
<p>La otra visualizaciÃ³n desarrollada es la de los resultados de la ejecuciÃ³n del clustering de clasificaciÃ³n de dÃ­as por temperatura. Esta interfaz presenta en la parte izquierda superior los grupos de clasificaciÃ³n de dÃ­as, pintados cada uno con un color asociativo. Debajo de los grupos se muestra un calendario en el que se encuentran coloreados los dÃ­as que han entrado en el estudio. El color de cada uno de los dÃ­as es el mismo que el del clÃºster al que ha sido asociado, con lo que se intenta conseguir un efecto de mapa de calor de los dÃ­as estudiados.</p>
<img src="images/ilu9.png" alt="VisualizaciÃ³n interactiva de los resultados del algoritmo de clustering"></img>
<p>En el panel central de la aplicaciÃ³n web se tiene un grÃ¡fico, hecho con la librerÃ­a Highcharts, en el que poder ver la comparativa entre los valores de los centroides de los clÃºster (seleccionables estos a travÃ©s del panel anterior) y el valor medio de los cuartos de hora de un dÃ­a, tambiÃ©n seleccionable desde el calendario.</p>
<p>Con esta interfaz, el usuario puede interactuar con los dÃ­as y analizar las caracterÃ­sticas del resultado de cada grupo, para luego catalogarlos: grupo de dÃ­as cÃ¡lidos, de dÃ­as de frÃ­oâ€¦ AdemÃ¡s, puede sacar conclusiones en cuanto al cambio del tiempo con el paso de los dÃ­as gracias a la visualizaciÃ³n del calendario.</p>
</div>
</div>
</div>
</div>
        <!-- Bootstrap core JavaScript
    ================================================== -->
        <!-- Placed at the end of the document so the pages load faster -->
        <script src="http://code.jquery.com/jquery-2.1.3.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
        <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
        <script src="https://raw.githubusercontent.com/twbs/bootstrap/master/docs/assets/js/ie10-viewport-bug-workaround.js"></script>
        <!-- Google Analytics script -->
        <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-54491895-1");
            pageTracker._trackPageview();
            } catch(err) {}
        </script>
                <script type="text/javascript">
                $(document).ready(function(){
                    $(window).bind('scroll', function() {
                        var navHeight = $("#box1").height();
                        ($(window).scrollTop() > navHeight) ? $('nav').addClass('goToTop') : $('nav').removeClass('goToTop');
                    });
                });
        </script>
    </body>
</html>
